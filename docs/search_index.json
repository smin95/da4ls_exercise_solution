[
["index.html", "Data Analysis for the Life Sciences with R: Exercise Solutions Welcome! Acknowledgment Frequently Asked Questions Contribution License Etc", " Data Analysis for the Life Sciences with R: Exercise Solutions Seung Hyun (Sam) Min 2020-12-14 Welcome! This book contains unofficial exercise solutions for the book Data Analysis for the Life Sciences with R by Rafael A. Irizarry and Michael I. Love. The PDF copy of the book is available for free and the physical copy is available in Amazon. Acknowledgment I would like to thank Rafael A. Irizarry and Michael I. Love for writing this wonderful book, and my friends who encouraged me to undertake this project. Frequently Asked Questions You can read the FAQs in the github page. Contribution If you spot any mistakes in the solution manual, please pull-request on Github or email me sammin95@gmail.com. I will then acknowledge you as a contributor to this project. License This work is licensed under a Creative Commons Attribution 4.0 International License. Etc If you like this solution, please check out my Youtube video and press the like button! Thanks! "],
["getting-started.html", "Chapter 1 Getting started", " Chapter 1 Getting started Since this chapter does not deal with statistics, I have decided to skip this chapter altogether. Before reading DA4LS with R The book gives a brief introduction to R. But I do not think this is enough. The codes in the later part of the book can get quite complicated (especially from Chapter 6). If you do not know R (or have no coding experience), I suggest you read Chapters 5, 15, 19-21 of R for Data Science by Hadley Wickham and Garrett Grolemund; these chapters discuss data transformation, factors, custom functions, vectors and iterations (ex. for loops, sapply). These concepts are deeply embeded in the codes throughout the book. There is also matrix algebra (ex. singular value decomposition) in this book (from Chapter 4). However, the book reviews matrix algebra briefly. If you have not taken a course in linear algebra, I suggest that you spend some extra time reviewing key concepts such as matrix multiplication, dot product, orthogonal matrix, inverse matrix and square matrix before reading Chapter 4. Here is a link to Khan Academy. When you are going through Chapter 8, you might also have you look up for extra resource on principal component analysis; I recommend this Youtube video by StatQuest. Also, Chapter 10 is a continuation of Chapter 8, so I suggest you read Chapter 10 (batch effect) before Chapter 9 (machine learning). "],
["inference.html", "Chapter 2 Inference 2.7 Exercises 2.9 Exercises 2.11 Exercises 2.13 Exercises 2.18 Exercises 2.21 Exercises 2.23 Exercises 2.25 Exercises", " Chapter 2 Inference Note: I have rephrased some parts of the questions for clarity. These changes are bolded. Due to the random numbers, the exact values of the answers, despite the same seeds, might differ. So please be mindful of that. First, upload necessary package(s). library(dplyr) # uplaods the functions filter() and %&gt;% ## Warning: package &#39;dplyr&#39; was built under R version 3.5.3 ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(rafalib) # important for plotting with base R ## Warning: package &#39;rafalib&#39; was built under R version 3.5.2 2.7 Exercises If you have not downloaded the data before, #dir &lt;- &quot;https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/&quot; #filename &lt;- &quot;femaleControlsPopulation.csv&quot; #url &lt;- paste0(dir, filename) #x &lt;- unlist(read.csv(url)) Or if you already have downloaded the data and they are in the directory, then just upload it. dat &lt;- read.csv(&#39;femaleControlsPopulation.csv&#39;) bodyweight &lt;- dplyr::select(dat, Bodyweight) x &lt;- unlist(bodyweight) # or use pipe %&gt;% x &lt;- read.csv(&#39;femaleControlsPopulation.csv&#39;) %&gt;% dplyr::select(Bodyweight) %&gt;% unlist() Check out what unlist does by typing ?unlist in the command. The second method is more concise because of the pipe %&gt;%, which allows multiple lines of commands to be in one continuous line. Question 1 What is the average of these weights? mean(x) ## [1] 23.89338 Question 2 After setting the seed at 1, set.seed(1) take a random sample size 5. What is the absolute value (use abs) of the difference between the average of the sample and the average of all the values? set.seed(1) avg_sample &lt;- mean(sample(x,5)) # average of the sample of 5 avg_pop &lt;- mean(x) # average of all values abs(avg_sample - avg_pop) # absolute difference ## [1] 0.2706222 Question 3 After setting the seed at 5, set.seed(5) take a random sample size 5. What is the absolute value (use abs) of the difference between the average of the sample and the average of all the values? set.seed(5) avg_sample &lt;- mean(sample(x,5)) # average of the sample of 5 avg_pop &lt;- mean(x) # average of all values abs(avg_sample - avg_pop) # absolute difference ## [1] 1.433378 Question 4 Why are the answers from 2 and 3 different? set.seed(1) # question 2 a &lt;- sample(x,5) a ## Bodyweight60 Bodyweight84 Bodyweight128 Bodyweight202 ## 21.51 28.14 24.04 23.45 ## Bodyweight45 ## 23.68 set.seed(5) # question 3 b &lt;- sample(x,5) b ## Bodyweight46 Bodyweight154 Bodyweight205 Bodyweight64 ## 21.86 20.30 22.95 21.92 ## Bodyweight24 ## 25.27 identical(a,b) # these two samples are not identical ## [1] FALSE Notice that samples a and b differ. Since the seeds were different (1 vs 5), different random numbers were generated. Therefore, the answer is C: Because the average of the samples is a random variable. Question 5 Set the seed at 1, then using a for-loop take a random sample of 5 mice in 1,000 times. Save these averages. What percent of these 1,000 averages are more than 1 gram away from the average of x? set.seed(1) n &lt;- 1000 res &lt;- vector(&#39;double&#39;,n) for (i in seq(n)) { avg_sample &lt;- mean(sample(x,5)) res[[i]] &lt;- avg_sample } mean(abs(res-mean(x)) &gt; 1) ## [1] 0.498 To make a for loop work in R, an empty vector needs to be created first. This can be achieved with the function vector. In this example, the empty vector is res (short for result). In the for loop, each average (avg_sample) from one repetition gets stored in res. Question 6 We are now going to increase the number of times we redo the sample from 1,000 to 10,000. Set the seed at 1, then using a for-loop take a random sample of 5 mice 10,000 times. Save these averages. What percent of these 10,000 averages are more than 1 gram away from the average of x? set.seed(1) n &lt;- 10000 res &lt;- vector(&#39;double&#39;,n) for (i in seq(n)) { avg_sample &lt;- mean(sample(x,5)) res[[i]] &lt;- avg_sample } mean(abs(res-mean(x)) &gt; 1) ## [1] 0.4976 Question 7 Note that the answers to 5 and 6 barely changed. This is expected. The way we think about the random value distributions is as the distribution of the list of values obtained if we repeated the experiment an infinite number of times. On a computer, we can’t perform an infinite number of iterations so instead, for our examples, we consider 1,000 to be large enough, thus 10,000 is as well. Now if instead we change the sample size, then we change the random variable and thus its distribution. Set the seed at 1, then using a for-loop take a random sample of 50 mice 1,000 times. Save these averages. What percent of these 1,000 averages are more than 1 gram away from the average of x? set.seed(1) n &lt;- 1000 res &lt;- vector(&#39;double&#39;,n) for (i in seq(n)) { avg_sample &lt;- mean(sample(x,50)) res[[i]] &lt;- avg_sample } mean(abs(res-mean(x)) &gt; 1) ## [1] 0.019 Question 8 Use a histogram to “look” at the distribution of averages we get with a sample size of 5 and sample size of 50. How would you say they differ? # sample size = 5 set.seed(1) n &lt;- 1000 res5 &lt;- vector(&#39;double&#39;,n) for (i in seq(n)) { avg_sample &lt;- mean(sample(x,5)) res5[[i]] &lt;- avg_sample } sd(res5) # standard deviation = spread of the histogram ## [1] 1.52445 # sample size = 50 set.seed(1) n &lt;- 1000 res50 &lt;- vector(&#39;double&#39;,n) for (i in seq(n)) { avg_sample &lt;- mean(sample(x,50)) res50[[i]] &lt;- avg_sample } sd(res50) # standard deviation = spread of the histogram ## [1] 0.4260116 The standard deviation of res50 is smaller than that of res5 because of the difference in the sample sizes. A higher standard deviation leads to a wider histogram. See two figures below. mypar(1,2) # plot histograms hist(res5) hist(res50) mypar is a function from the package rafalib. It helps to align multiple plots in a single plot. mypar(1,1) contains one panel only, mypar(2,1) contains 2 rows of panels and 1 column, mypar(1,2) contains 1 row of panels and 2 columns, etc. Type ?mypar for more information. You will be using this function to plot a graph throughout the entire book. hist plots a histogram. The answer is B: They both look normal, but with a sample size of 50 the spread is smaller. Question 9 For the last set of averages, the ones obtained from a sample size of 50, what percent are between 23 and 25? mean((res50 &gt;=23) &amp; (res50 &lt;= 25)) ## [1] 0.976 Question 10 Now ask the same question of a normal distribution with average 23.9 and standard deviation 0.43. pnorm(25,23.9,0.43) - pnorm(23,23.9,0.43) ## [1] 0.9765648 The answers to 9 and 10 were very similar. This is because we can approximate the distribution of the sample average with a normal distribution. We will learn more about the reason for this next. 2.9 Exercises If you have not downloaded the data before: dir &lt;- &quot;https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/&quot; filename &lt;- &quot;mice_pheno.csv&quot; url &lt;- paste0(dir, filename) dat &lt;- read.csv(url) dat &lt;- na.omit(dat) If you have the data already in your directory: raw_data &lt;- read.csv(&#39;mice_pheno.csv&#39;) dat &lt;- na.omit(raw_data) Question 1 Use dplyr to create a vector x with the body weight of all males on the control (chow) diet. What is this population’s average? x &lt;- dat %&gt;% filter(Sex == &#39;M&#39; &amp; Diet == &#39;chow&#39;) %&gt;% dplyr::select(Bodyweight) %&gt;% unlist() mean(x) ## [1] 30.96381 Throughout the book, I will be using %&gt;% for brevity. If you don’t understand it, please check out Chapter 18 of *R for Data Science. Question 2 Now use the rafalib package and use the popsd function to compute the population standard deviation. popsd(x) ## [1] 4.420501 popsd and sd are slightly different. sd calculates the standard deviation of the sample size, so the denominator that it uses to compute SD is n-1. Function var also uses denominator n-1 to calculate variance. However, popsd (which is from rafalib package) uses denominator n. Question 3 Set the seed at 1. Take a random sample X of size 25 from x. What is the sample average? set.seed(1) samp_x &lt;- sample(x,25) # sample of x mean(samp_x) ## [1] 32.0956 Question 4 Use dplyr to create a vector y with the body weight of all males on the high fat (hf) diet. What is this population’s average? y &lt;- dat %&gt;% filter(Sex == &#39;M&#39; &amp; Diet == &#39;hf&#39;) %&gt;% dplyr::select(Bodyweight) %&gt;% unlist() mean(y) ## [1] 34.84793 Question 5 Now use the rafalib package and use the popsd function to compute the population standard deviation. popsd(y) ## [1] 5.574609 Question 6 Set the seed at 1. Take a random sample Y of size 25 from y. What is the sample average? set.seed(1) samp_y &lt;- sample(y,25) mean(samp_y) ## [1] 34.768 Question 7 What is the difference in absolute value between \\(\\bar{y}-\\bar{x}\\) and \\(\\bar{Y}-\\bar{X}\\)? pop_diff &lt;- mean(y) - mean(x) sample_diff &lt;- mean(samp_y) - mean(samp_x) abs(sample_diff - pop_diff) ## [1] 1.211716 Question 8 Repeat the above for females. Make sure to set the seed to 1 before each sample call. What is the difference in absolute value between \\(\\bar{y}-\\bar{x}\\) and \\(\\bar{Y}-\\bar{X}\\)? chow_f_pop &lt;- dat %&gt;% filter(Sex == &#39;F&#39; &amp; Diet == &#39;chow&#39;) %&gt;% dplyr::select(Bodyweight) %&gt;% unlist() # x hf_f_pop &lt;- dat %&gt;% filter(Sex == &#39;F&#39; &amp; Diet == &#39;hf&#39;) %&gt;% dplyr::select(Bodyweight) %&gt;% unlist() # y set.seed(1) sample_chow_f_pop &lt;- sample(chow_f_pop, 25) # X set.seed(1) sample_hf_f_pop &lt;- sample(hf_f_pop,25) # Y pop_diff &lt;- mean(hf_f_pop) - mean(chow_f_pop) # y - x sample_diff &lt;- mean(sample_hf_f_pop) - mean(sample_chow_f_pop) # Y - X abs(sample_diff - pop_diff) ## [1] 0.7364828 Question 9 For the females, our sample estimates were closer to the population difference than with males. What is a possible explanation for this? ans &lt;- c(popsd(hf_f_pop), popsd(chow_f_pop), popsd(y), popsd(x)) names(ans) &lt;- c(&#39;hf female&#39;, &#39;chow female&#39;, &#39;hf male&#39;, &#39;chow male&#39;) ans ## hf female chow female hf male chow male ## 5.069870 3.416438 5.574609 4.420501 The answer is A: The population variance of the females is smaller than that of the males; thus, the sample variable has less variability. 2.11 Exercises If you have not downloaded the data before: dir &lt;- &quot;https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/&quot; filename &lt;- &quot;mice_pheno.csv&quot; url &lt;- paste0(dir, filename) dat &lt;- read.csv(url) dat &lt;- na.omit(dat) If you have the data already in your directory: raw_data &lt;- read.csv(&#39;mice_pheno.csv&#39;) dat &lt;- na.omit(raw_data) Question 1 If a list of numbers has a distribution that is well approximated by the normal distribution, what proportion of these numbers are within one standard deviation away from the list’s average? pnorm(1) - pnorm(-1) ## [1] 0.6826895 Question 2 What proportion of these numbers are within two standard deviations away from the list’s average? pnorm(2) - pnorm(-2) ## [1] 0.9544997 Question 3 What proportion of these numbers are within three standard deviations away from the list’s average? pnorm(3) - pnorm(-3) ## [1] 0.9973002 Question 4 Define y to be the weights of males on the control diet. What proportion of the mice are within one standard deviation away from the average weight (remember to use popsd for the population sd)? y &lt;- dat %&gt;% filter(Sex == &#39;M&#39; &amp; Diet == &#39;chow&#39;) %&gt;% dplyr::select(Bodyweight) %&gt;% unlist() z_score &lt;- (y - mean(y))/popsd(y) # get t-statistic (i.e., z score) mean(abs(z_score) &lt;= 1) ## [1] 0.6950673 mean(abs(y - mean(y)) &lt;= popsd(y)) ## [1] 0.6950673 It doesn’t matter which solution you use as long as you have the same answer. Question 5 What proportion of these numbers are within two standard deviations away from the list’s average? mean(abs(z_score) &lt;= 2) ## [1] 0.9461883 mean(abs(y - mean(y)) &lt;= 2*popsd(y)) ## [1] 0.9461883 It doesn’t matter which solution you use as long as you have the same answer. Question 6 What proportion of these numbers are within three standard deviations away from the list’s average? mean(abs(z_score) &lt;= 3) ## [1] 0.9910314 mean(abs(y - mean(y)) &lt;= 3*popsd(y)) ## [1] 0.9910314 It doesn’t matter which solution you use as long as you have the same answer. Question 7 Note that the numbers for the normal distribution and our weights are relatively close. Also, notice that we are indirectly comparing quantiles of the normal distribution to quantiles of the mouse weight distribution. We can actually compare all quantiles using a qq-plot. Which of the following best describes the qq-plot comparing mouse weights to the normal distribution? mypar(1,1) qqnorm(y) qqline(y) The answer is C: The mouse weights are well approximated by the normal distribution, although the larger values (right tail) are larger than predicted by the normal.This is consistent with the differences seen between question 3 and 6. Question 8 Create the above qq-plot for the four populations: male/females on each of the two diets. What is the most likely explanation for the mouse weights being well approximated? What is the best explanation for all these being well approximated by the normal distribution? mc &lt;- dat %&gt;% filter(Sex == &#39;M&#39; &amp; Diet == &#39;chow&#39;) %&gt;% dplyr::select(Bodyweight) %&gt;% unlist() mhf &lt;- dat %&gt;% filter(Sex == &#39;M&#39; &amp; Diet == &#39;hf&#39;) %&gt;% dplyr::select(Bodyweight) %&gt;% unlist() fc &lt;- y &lt;- dat %&gt;% filter(Sex == &#39;F&#39; &amp; Diet == &#39;chow&#39;) %&gt;% dplyr::select(Bodyweight) %&gt;% unlist() fhf &lt;- y &lt;- dat %&gt;% filter(Sex == &#39;F&#39; &amp; Diet == &#39;hf&#39;) %&gt;% dplyr::select(Bodyweight) %&gt;% unlist() mypar(2,2) qqnorm(mc, main = &#39;male control pop&#39;) qqline(mc) qqnorm(mhf, main = &#39;male high fat pop&#39;) qqline(mhf) qqnorm(fc, main = &#39;female control pop&#39;) qqline(fc) qqnorm(fhf, main = &#39;female high fat pop&#39;) qqline(fhf) The answer is B: This just happens to be how nature behaves. Perhaps the result of many biological factors averaging out. Question 9 Here we are going to use the function replicate to learn about the distribution of random variables. All the above exercises relate to the normal distribution as an approximation of the distribution of a fixed list of numbers or a population. We have not yet discussed probability in these exercises. If the distribution of a list of numbers is approximately normal, then if we pick a number at random from this distribution, it will follow a normal distribution. However, it is important to remember that stating that some quantity has a distribution does not necessarily imply this quantity is random. Also, keep in mind that this is not related to the central limit theorem. The central limit applies to averages of random variables. Let’s explore this concept. We will now take a sample of size 25 from the population of males on the chow diet. The average of this sample is our random variable. We will use the replicate to observe 10,000 realizations of this random variable. Set the seed at 1, generate these 10,000 averages. Make a histogram and qq-plot of these 10,000 numbers against the normal distribution. We can see that, as predicted by the CLT, the distribution of the random variable is very well approximated by the normal distribution. y &lt;- filter(dat, Sex==&quot;M&quot; &amp; Diet==&quot;chow&quot;) %&gt;% dplyr::select(Bodyweight) %&gt;% unlist avgs &lt;- replicate(10000, mean( sample(y, 25))) mypar(1,2) hist(avgs) qqnorm(avgs) qqline(avgs) What is the average of the distribution of the sample average? m &lt;- 10000 n &lt;- 25 y &lt;- filter(dat, Sex==&quot;M&quot; &amp; Diet==&quot;chow&quot;) %&gt;% dplyr::select(Bodyweight) %&gt;% unlist set.seed(1) avg_list &lt;- replicate(m, { mean(sample(y,25)) }) mypar(1,2) hist(avg_list) # distribution qqnorm(avg_list) # qq-plot qqline(avg_list) mean(avg_list) # mean of the sample averages ## [1] 30.95581 Question 10 What is the standard deviation of the distribution of sample averages? popsd(avg_list) ## [1] 0.8368192 Question 11 According to the CLT, the answer to exercise 9 should be the same as mean(y). You should be able to confirm that these two numbers are very close. Which of the following does the CLT tell us should be close to your answer to exercise 10? popsd(y)/sqrt(25) # answer is C ## [1] 0.8841001 Question 12 In practice we do not know \\(\\sigma\\) (popsd(y)) which is why we can’t use the CLT directly. This is because we see a sample and not the entire distribution. We also can’t use popsd(avgs) because to construct averages, we have to take 10,000 samples and this is never practical. We usually just get one sample. Instead we have to estimate popsd(y). As described, what we use is the sample standard deviation. Set the seed at 1, using the replicate function, create 10,000 samples of 25 and now, instead of the sample average, keep the standard deviation. Look at the distribution of the sample standard deviations. It is a random variable. The real population SD is about 4.5. What proportion of the sample SDs are below 3.5? m &lt;- 10000 set.seed(1) sd_list &lt;- replicate(m, { sd(sample(y,25)) }) mypar(1,1) hist(sd_list) mean(sd_list &lt;= 3.5) ## [1] 0.0964 Question 13 What the answer to question 12 reveals is that the denominator of the t-test is a random variable. By decreasing the sample size, you can see how this variability can increase. It therefore adds variability. The smaller the sample size, the more variability is added. The normal distribution stops providing a useful approximation. When the distribution of the population values is approximately normal, as it is for the weights, the t-distribution provides a better approximation. We will see this later on. Here we will look at the difference between the t-distribution and normal. Use the function qt and qnorm to get the quantiles of x=seq(0.0001,0.9999,len=300). Do this for degrees of freedom 3, 10, 30, and 100. Which of the following is true? x = seq(0.0001, 0.9999, len = 300) df_list &lt;- c(3,10,30,100) mypar(2,2) for (i in seq_along(df_list)) { qqnorm(qt(x,df_list[i]), main = df_list[i]) } The answer is C: The t-distribution has larger tails up until 30 degrees of freedom, at which point it is practically the same as the normal distribution. 2.13 Exercises dir &lt;- &quot;https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/&quot; filename &lt;- &quot;femaleMiceWeights.csv&quot; url &lt;- paste0(dir, filename) dat &lt;- read.csv(url) Question 1 The CLT is a result from probability theory. Much of probability theory was originally inspired by gambling. This theory is still used in practice by casinos. For example, they can estimate how many people need to play slots for there to be a 99.9999% probability of earning enough money to cover expenses. Let’s try a simple example related to gambling. Suppose we are interested in the proportion of times we see a 6 when rolling n=100 die. This is a random variable which we can simulate with x=sample(1:6, n, replace=TRUE) and the proportion we are interested in can be expressed as an average: mean(x==6). Because the die rolls are independent, the CLT applies. We want to roll n dice 10,000 times and keep these proportions. This random variable (proportion of 6s) has mean p=1/6 and variance p*(1-p)/n. So according to CLT z = (mean(x==6) - p) / sqrt(p*(1-p)/n) should be normal with mean 0 and SD 1. Set the seed to 1, then use replicate to perform the simulation, and report what proportion of times z was larger than 2 in absolute value (CLT says it should be about 0.05). n &lt;- 100 B &lt;- 10000 p &lt;- 1/6 set.seed(1) res_list &lt;- replicate(B, { x = sample(1:6,n, replace = T) z &lt;- (mean(x==6)-p) / sqrt(p*(1-p)/n) return(z) }) mean(abs(res_list) &gt; 2) ## [1] 0.0424 Question 2 For the last simulation you can make a qqplot to confirm the normal approximation. Now, the CLT is an asymptotic result, meaning it is closer and closer to being a perfect approximation as the sample size increases. In practice, however, we need to decide if it is appropriate for actual sample sizes. Is 10 enough? 15? 30? In the example used in exercise 1, the original data is binary (either 6 or not). In this case, the success probability also affects the appropriateness of the CLT. With very low probabilities, we need larger sample sizes for the CLT to “kick in”. Run the simulation from exercise 1, but for different values of p and n. For which of the following is the normal approximation best? Ps &lt;- c(0.01,0.5) Ns &lt;- c(5,30,100) set.seed(1) question2 &lt;- function(n,p, B = 10000) { res_list &lt;- replicate(B, { sides &lt;- 1/p x = sample(1:sides, n, replace = T) z &lt;- (mean(x==1)-p) / sqrt(p*(1-p)/n) return(z) }) } mypar(2,2) qqnorm(question2(5,0.5), main = &#39;n=5, p=0.5&#39;) qqnorm(question2(30,0.5), main = &#39;n=30, p=0.5&#39;) # the answer is B qqnorm(question2(30,0.01), main = &#39;n=30, p=0.01&#39;) qqnorm(question2(100,0.01), main = &#39;n=100, p=0.01&#39;) mypar(1,2) hist(question2(30,0.5), main = &#39;n=30, p=0.5&#39;) hist(question2(100,0.01), main = &#39;n=100, p=0.01&#39;) The answer is B, n = 30, p = 0.5. I created a custom function for this question. However, another approach (and maybe more concise) is to use a for loop. This is tricky question, primarily because not all dice has number 6 (as is the case in Question 1, mean(x==6)). So you had to calculate the probability where the dice ends up in another side by modifying the code; since all dice has sdie 1, mean(x==1) seems like a safe choice. Also, the number of the sides for each die changes since it is defined by the p value. For instance, if p equals 0.01 for side 1, then there are 100 sides total (1/0.01 = 100). Question 3 As we have already seen, the CLT also applies to averages of quantitative data. A major difference with binary data, for which we know the variance is p(1-p), is that with quantitative data we need to estimate the population standard deviation. In several previous exercises we have illustrated statistical concepts with the unrealistic situation of having access to the entire population. In practice, we do not have access to entire populations. Instead, we obtain one random sample and need to reach conclusions analyzing that data. dat is an example of a typical simple dataset representing just one sample. We have 12 measurements for each of two populations: X &lt;- filter(dat, Diet==&quot;chow&quot;) %&gt;% dplyr::select(Bodyweight) %&gt;% unlist Y &lt;- filter(dat, Diet==&quot;hf&quot;) %&gt;% dplyr::select(Bodyweight) %&gt;% unlist We think of X as a random sample from the population of all mice in the control diet and Y as a random sample from the population of all mice in the high fat diet. Define the parameter \\(\\mu_x\\) as the average of the control population. We estimate this parameter with the sample average \\(\\bar{X}\\). What is the sample average? mean(X) ## [1] 23.81333 Question 4 We don’t know \\(\\mu_x\\), but want to use \\(\\bar{X}\\) to understand \\(\\mu_x\\). Which of the following uses CLT to understand how well \\(\\bar{X}\\) approximates \\(\\mu_x\\)? The answer is 0. Z refers to t-statistic (something that the book does not explicitly highlight), which is not raw data. Instead, we use raw data and then compute t-statistic. This is the value that is used to compute p-value based on the normal distribution. In the case of z-score or t-statistic, it is 0 at the mean of the sample due to its mathematical definition. Question 6 The result of 4 and 5 tell us that we know the distribution of the difference between our estimate and what we want to estimate, but don’t know. However, the equation involves the population standard deviation \\(\\sigma_X\\), which we don’t know. Given what we discussed, what is your estimate of \\(\\sigma_x\\)? sd(X) ## [1] 3.022541 Question 7 Use the CLT to approximate the probability that our estimate \\(\\bar{X}\\) is off by more than 2 grams from \\(\\mu_x\\). z_score &lt;- 2/(sqrt(sd(X)^2/12)) pnorm(-z_score) + 1- pnorm(z_score) ## [1] 0.02189533 Question 8 Now we introduce the concept of a null hypothesis. We don’t know \\(\\mu_x\\) nor \\(mu_y\\). We want to quantify what the data say about the possibility that the diet has no effect: \\(\\mu_x = \\mu_y\\). If we use CLT, then we approximate the distribution of \\(\\bar{X}\\) as normal with mean \\(mu_X\\) and standard deviation of \\(\\frac{\\sigma_X}{\\sqrt{M}}\\) and the distribution of \\(\\bar{Y}\\) and standard deviation of \\(\\frac{\\sigma_y}{\\sqrt{N}}\\), with \\(M\\) and \\(N\\) as the sample sizes for \\(X\\) and \\(Y\\) respectively, in this case 12. This implies that the difference \\(\\bar{Y} - \\bar{X}\\) has mean \\(0\\). We described that the standard deviation of this statistic (the standard error) is \\(SE(\\bar{Y} - \\bar{X}) = \\sqrt{\\sigma_y^2/12 + \\sigma_x^2/12}\\) and that we estimate the population standard deviations \\(\\sigma_x\\) and \\(\\sigma_y\\) with the sample estimates. What is the estimate of \\(SE(\\bar{Y} - \\bar{X}) = \\sqrt{\\sigma_y^2/12 + \\sigma_x^2/12}\\)? sqrt((sd(X)^2 + sd(Y)^2)/12) ## [1] 1.469867 Question 9 So now we can compute \\(\\bar{Y}-\\bar{X}\\) as well as an estimate of this standard error and construct a t-statistic. What is this t-statistic? (mean(Y) - mean(X))/ sqrt((sd(X)^2 + sd(Y)^2)/12) ## [1] 2.055174 This is a good formula to memorize because it will return in later chapters. Knowing this formula can enable us to compute p-values from scratch. Question 10 If we apply the CLT, what is the distribution of this t-statistic? The answer is A: Normal with mean 0 and standard deviation 1. T-statistic is z-score, so the values are standardized to the sample mean. Therefore, the mean is 0. Question 11 Now we are ready to compute a p-value using the CLT. What is the probability of observing a quantity as large as what we computed for t-statistic in Question 9, when the null distribution is true? tstat &lt;- (mean(Y) - mean(X))/ sqrt((sd(X)^2 + sd(Y)^2)/12) # from question 9 2*(1-pnorm(tstat)) ## [1] 0.0398622 Question 12 CLT provides an approximation for cases in which the sample size is large. In practice, we can’t check the assumption because we only get to see 1 outcome (which you computed above). As a result, if this approximation is off, so is our p-value. As described earlier, there is another approach that does not require a large sample size, but rather that the distribution of the population is approximately normal. We don’t get to see this distribution so it is again an assumption, although we can look at the distribution of the sample with qqnorm(X) and qqnorm(Y). If we are willing to assume this, then it follows that the t-statistic follows t- distribution. What is the p-value under the t-distribution approximation? Hint: use the t.test function. mypar(1,2) qqnorm(X, main = &#39;Theoretical normal quantiles vs X&#39;) qqline(X) qqnorm(Y, main = &#39;Theoretical normal quantiles vs Y&#39;) qqline(Y) t.test(X,Y)$p.value ## [1] 0.05299888 Question 13 With the CLT distribution, we obtained a p-value smaller than 0.05 and with the t-distribution, one that is larger. They can’t both be right. What best describes the difference? The answer is B: These are two different assumptions. The t-distribution accounts for the variability introduced by the estimation of the standard error and thus, under the null, large values are more probable under the null distribution. 2.18 Exercises For these exercises we will load the babies dataset from babies.txt. We will use this data to review the concepts behind the p-values and then test confidence interval concepts. babies &lt;- read.table(&quot;babies.txt&quot;, header=TRUE) This is a large dataset (1,236 cases), and we will pretend that it contains the entire population in which we are interested. We will study the differences in birth weight between babies born to smoking and non-smoking mothers. First, let’s split this into two birth weight datasets: one of birth weights to non-smoking mothers and the other of birth weights to smoking mothers. bwt.nonsmoke &lt;- filter(babies, smoke==0) %&gt;% dplyr::select(bwt) %&gt;% unlist bwt.smoke &lt;- filter(babies, smoke==1) %&gt;% dplyr::select(bwt) %&gt;% unlist Now, we can look for the true population difference in means between smoking and non-smoking birth weights. library(rafalib) mean(bwt.nonsmoke)-mean(bwt.smoke) ## [1] 8.937666 popsd(bwt.nonsmoke) ## [1] 17.38696 popsd(bwt.smoke) ## [1] 18.08024 The population difference of mean birth weights is about 8.9 ounces. The standard deviations of the nonsmoking and smoking groups are about 17.4 and 18.1 ounces, respectively. As we did with the mouse weight data, this assessment interactively reviews inference concepts using simulations in R. We will treat the babies dataset as the full population and draw samples from it to simulate individual experiments. We will then ask whether somebody who only received the random samples would be able to draw correct conclusions about the population. We are interested in testing whether the birth weights of babies born to non-smoking mothers are significantly different from the birth weights of babies born to smoking mothers. Question 1 Set the seed at 1 and obtain two samples, each of size N = 25, from non-smoking mothers (dat.ns) and smoking mothers (dat.s). Compute the t-statistic (call it tval). N &lt;- 25 set.seed(1) dat.ns &lt;- sample(bwt.nonsmoke,N) dat.s &lt;- sample(bwt.smoke,N) tval &lt;- (mean(dat.s) - mean(dat.ns)) / sqrt(var(dat.s)/N + var(dat.ns)/N) t.test(dat.s,dat.ns)$statistic[[1]] ## [1] -2.120904 pt(tval, df = N*2-2)*2 ## [1] 0.03912225 Question 2 Recall that we summarize our data using a t-statistics because we know that in situations where the null hypothesis is true (what we mean when we say “under the null”) and the sample size is relatively large, this t-value will have an approximate standard normal distribution. Because we know the distribution of the t-value under the null, we can quantitatively determine how unusual the observed t-value would be if the null hypothesis were true. The standard procedure is to examine the probability a t-statistic that actually does follow the null hypothesis would have larger absolute value than the absolute value of the t-value we just observed- this is called a two-sided test. We have computed these by taking one minus the area under the standard normal curve between -abs(tval) and abs(tval). In R, we can do this by using the pnorm function, which computes the area under a normal curve from negative infinity up to the value given as its first argument. What is the estimated p-value? (pnorm(tval) + 1 - pnorm(-tval)) ## [1] 0.03392985 Question 3 Because of the symmetry of the standard normal distribution, there is a simpler way to calculate the probability that a t-value under the null could have a larger absolute value than tval. Choose a simplified calculation from the four choices. 2*pnorm(-abs(tval)) ## [1] 0.03392985 Question 4 By reporting only p-values, many scientific publications provide an incomplete story of their findings. As we have mentioned, with very large sample sizes, scientifically insignificant differences between two groups can lead to small p-values. Confidence intervals are more informative as they include the estimate itself. Our estimate of the difference between babies of smokers and non-smokers: mean(dat.s) - mean( dat.ns). If we use the CLT, what quantity would we add and subtract to this estimate to obtain a 99% confidence interval? mean(dat.s) - mean(dat.ns) ## [1] -9.92 Q &lt;- qnorm(0.5 + 0.99/2) se &lt;- sqrt(var(dat.ns)/N + var(dat.s)/N) c(-Q*se + mean(dat.s) - mean(dat.ns), mean(dat.s) - mean(dat.ns) + Q*se) ## [1] -21.967797 2.127797 print(Q*se) ## [1] 12.0478 Question 5 If instead of CLT, we use the t-distribution approximation, what do we add and subtract (use 2*N-2 degrees of freedom)? Qt &lt;- qt(0.5 + 0.99/2, df = N*2-2) se &lt;- sqrt(var(dat.ns)/N + var(dat.s)/N) c(-Qt*se + mean(dat.s) - mean(dat.ns), mean(dat.s) - mean(dat.ns) + Qt*se) ## [1] -22.465339 2.625339 t.test(dat.s, dat.ns) ## ## Welch Two Sample t-test ## ## data: dat.s and dat.ns ## t = -2.1209, df = 47.693, p-value = 0.03916 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -19.3258047 -0.5141953 ## sample estimates: ## mean of x mean of y ## 114.76 124.68 print(Qt*se) ## [1] 12.54534 Question 6 Why are the values from 4 and 5 so similar? The answer is C: N and thus the degrees of freedom is large enough to make the normal and t-distributions very similar. Question 7 Which of the following sentences about a Type I error is false? The answer is C: From the original data alone, you can tell whether you have made a Type I error. Question 8 Set the seed at 1 and take a random sample of \\(N = 5\\) measurements from each of the smoking and nonsmoking datasets. What is the p-value (use the t-test function)? N &lt;- 5 set.seed(1) ns_sample &lt;- sample(bwt.nonsmoke, N) s_sample &lt;- sample(bwt.smoke, N) t.test(ns_sample, s_sample)$p.value ## [1] 0.1366428 Question 9 The p-value is larger than 0.05 so using the typical cut-off, we would not reject. This is a type II error (false negative). Which of the following is not a way to decrease this type of error? The answer is C: Find a population for which the null is not true. Question 10 Set the seed at 1, then use the replicate function to repeat the code in Exercise 9 10,000 times. What proportion of the time do we reject at the 0.05 level? B &lt;- 10000 alpha &lt;- 0.05 set.seed(1) N &lt;- 5 res_list&lt;- replicate(B, { ns_sample &lt;- sample(bwt.nonsmoke, N) s_sample &lt;- sample(bwt.smoke, N) pval &lt;- t.test(ns_sample, s_sample)$p.value return(alpha &gt; pval) # this returns logical (i.e., TRUE if pval is smaller than 0.05 = alpha), and stores in the vector res_list. }) mean(res_list) ## [1] 0.0984 Question 11 Note that, not surprisingly, the power is lower than 10%. Repeat the exercise above for sample sizes of 30, 60, 90 and 120. Which of these four gives you power of about 80%? pval_calc &lt;- function(N) { ns_sample &lt;- sample(bwt.nonsmoke, N) s_sample &lt;- sample(bwt.smoke, N) pval &lt;- t.test(ns_sample, s_sample)$p.value return(pval) } Ns &lt;- c(30,60,90,120) B &lt;- 10000 alpha &lt;- 0.05 res_list &lt;- vector(&#39;double&#39;,length(Ns)) for (i in seq_along(Ns)) { res_list[[i]] &lt;- mean(replicate(B, pval_calc(Ns[[i]])) &lt; alpha) } names(res_list) &lt;- Ns print(res_list) # sample size of 60 gives power of 80% ## 30 60 90 120 ## 0.4933 0.7868 0.9344 0.9835 Sample size of 60 gives power of 80%. Question 12 Repeat Question 11, but now require an \\(\\alpha\\) level of 0.01. Which of these four gives you power of 80%? pval_calc &lt;- function(N) { ns_sample &lt;- sample(bwt.nonsmoke, N) s_sample &lt;- sample(bwt.smoke, N) pval &lt;- t.test(ns_sample, s_sample)$p.value return(pval) } Ns &lt;- c(30,60,90,120) B &lt;- 10000 alpha &lt;- 0.01 res_list &lt;- vector(&#39;double&#39;,length(Ns)) for (i in seq_along(Ns)) { res_list[[i]] &lt;- mean(replicate(B, pval_calc(Ns[[i]])) &lt; alpha) } names(res_list) &lt;- Ns print(res_list) # sample size of 90 gives power of 80% ## 30 60 90 120 ## 0.2461 0.5607 0.7932 0.9241 Sample size of 90 gives power of 80%. 2.21 Exercises We have used Monte Carlo simulation throughout this chapter to demonstrate statistical concepts; namely, sampling from the population. We mostly applied this to demonstrate the statistical properties related to inference on differences in averages. Here, we will consider examples of how Monte Carlo simulations are used in practice. Question 1 Imagine you are William Sealy Gosset and have just mathematically derived the distribution of the t-statistic when the sample comes from a normal distribution. Unlike Gosset you have access to computers and can use them to check the results. Let’s start by creating an outcome. Set the seed at 1, use rnorm to generate a random sample of size 5, \\(X_1,...,.X_5\\) from a standard normal distribution, then compute the t-statistic \\(t = \\sqrt{5}\\bar{X}/s\\) with \\(s\\) the sample standard deviation. What value do you observe? set.seed(1) n &lt;- 5 sample1 &lt;- rnorm(n) tstat &lt;- sqrt(5)*mean(sample1)/sd(sample1) tstat ## [1] 0.3007746 Question 2 You have just performed a Monte Carlo simulation using rnorm, a random number generator for normally distributed data. Gosset’s mathematical calculation tells us that the t-statistic defined in the previous exercise, a random variable, follows a t-distribution with \\(N-1\\) degrees of freedom. Monte Carlo simulations can be used to check the theory: we generate many outcomes and compare them to the theoretical result. Set the seed to 1, generate B = 1000 t-statistics as done in Question 1. What proportion is larger than 2? set.seed(1) samp &lt;- rnorm(5) tstat &lt;- sqrt(5)*samp/sd(samp) get_t &lt;- function(n) { samp &lt;- rnorm(n) tstat &lt;- sqrt(n)*mean(samp)/sd(samp) return(tstat) } set.seed(1) res_list &lt;- replicate(1000, get_t(5)) mean(res_list &gt; 2) ## [1] 0.068 Question 3 The answer to Question 2 is very similar to the theoretical prediction: 1-pt(2,df=4). We can check several such quantiles using qqplot function. To obtain quantiles for the t-distribution we can generate percentiles from just above 0 to just below 1: B=100; ps = seq(1/(B+1), 1-1/(B+1), len = B) and compute the quantiles with qt(ps, df=4). Now we can use qqplot to compare these theoretical quantiles to those obtained in Monte Carlo simulation. Use Monte Carlo simulation developed for Question 2 to corroborate that the t-statistic \\(t = \\sqrt{N}\\bar{X}/s\\) follows a t-distribution for several values of N. For which sample sizes does the approximation best work? B &lt;- 1000 ps = seq(1/(B+1), 1-1/(B+1),len=B) get_t &lt;- function(n) { samp &lt;- rnorm(n) tstat &lt;- sqrt(n)*mean(samp)/sd(samp) return(tstat) } Ns &lt;- c(5,10,50,100) mypar(2,2) set.seed(1) for (i in seq_along(Ns)) { res_list &lt;- replicate(1000, get_t(Ns[i])) theory_t &lt;- qt(ps,df=Ns[i]-1) qqplot(theory_t, res_list, main = paste0(&#39;sample size= &#39;,Ns[i]), xlab = &#39;theory&#39;, ylab = &#39;sim&#39;) abline(0,1) } The approximations are spot on for all sample sizes (answer choice C). Question 4 Use Monte Carlo simulation to corroborate that the t-statistic comparing two means and obtained with normally distributed (mean 0 and sd) data follows a t-distribution. In this case we will use the t.test function with var.equal=TRUE. With this argument the degrees of freedom will be df=2*N-2 with N the sample size. For which sample sizes does the approximation best work? ttestgenerator &lt;- function(n) { cases &lt;- rnorm(n) controls &lt;- rnorm(n) tstat &lt;- t.test(cases,controls)$statistic[[1]] return(tstat) } Ns &lt;- c(5,10,50,100) mypar(2,2) set.seed(1) for (i in seq_along(Ns)) { res_list &lt;- replicate(1000, ttestgenerator(Ns[i])) theory_t &lt;- qt(ps,df=2*Ns[i]-2) qqplot(theory_t, res_list, main = paste0(&#39;sample size= &#39;,Ns[i]), xlab = &#39;theory&#39;, ylab = &#39;sim&#39;) abline(0,1) } The approximations are spot on for all sample sizes (answer choice C). Question 5 Is the following statement true or false? If instead of generating the sample with X = rnorm(15), we generate it with binary data (either positive or negative 1 with probability 0.5) X = sample(c(-1,1),15,replace = TRUE) then the t-statistic tstat &lt;- sqrt(15) * mean(X) / sd(X) is approximated by a t-distribution with 14 degrees of freedom. set.seed(1) res_list &lt;- replicate(1000, { X &lt;- sample(c(-1,1),15,replace = T) tstat &lt;- sqrt(15) * mean(X)/sd(X) return(tstat) }) ps &lt;- seq(1/(B+1), 1-1/(B+1),len=B) theory_t &lt;- qt(ps,df=14) qqplot(res_list, theory_t) False. Instead, it is approximated by binomial distribution because the data are binary (only two values). Question 6 Is the following statement true or false? If instead of generating the sample with X = rnorm(N) with N = 1000, we generate it with binary data X = sample(c(-1,1),15,replace = TRUE) then the t-statistic tstat &lt;- sqrt(15) * mean(X) / sd(X) is approximated by a t-distribution with 999 degrees of freedom. set.seed(1) res_list &lt;- replicate(1000, { X &lt;- sample(c(-1,1),1000,replace = T) tstat &lt;- sqrt(1000) * mean(X)/sd(X) return(tstat) }) B&lt;-1000 ps &lt;- seq(1/(B+1), 1-1/(B+1),len=B) theory_t &lt;- qt(ps,df=999) qqplot(res_list, theory_t) abline(0,1) True. Question 7 We can derive approximation of the distribution of the sample average or the t-statistic theoretically. However, suppose we are interested in the distribution of a statistic for which a theoretical approximation is not immediately obvious. Consider the sample median as an example. Use a Monte Carlo to determine which of the following best approximates the median of a sample taken from normally distributed population with mean 0 and standard deviation 1. The answer is A: Just like for the average, the sample median is approximately normal with mean 0 and SD \\(1/\\sqrt{N}\\). 2.23 Exercises babies &lt;- read.table(&quot;babies.txt&quot;, header=TRUE) bwt.nonsmoke &lt;- filter(babies, smoke==0) %&gt;% dplyr::select(bwt) %&gt;% unlist bwt.smoke &lt;- filter(babies, smoke==1) %&gt;% dplyr::select(bwt) %&gt;% unlist Question 1 We will generate the following random variable based on a sample size of 10 and observe the following difference: N=10 set.seed(1) nonsmokers &lt;- sample(bwt.nonsmoke , N) smokers &lt;- sample(bwt.smoke , N) obs &lt;- mean(smokers) - mean(nonsmokers) The question is whether this observed difference is statistically significant. We do not want to rely on the assumptions needed for the normal or t-distribution approximations to hold, so instead we will use permutations. We will reshuffle the data and recompute the mean. We can create one permuted sample with the following code: dat &lt;- c(smokers,nonsmokers) shuffle &lt;- sample( dat ) smokersstar &lt;- shuffle[1:N] nonsmokersstar &lt;- shuffle[(N+1):(2*N)] mean(smokersstar)-mean(nonsmokersstar) ## [1] -8.5 The last value is one observation from the null distribution we will construct. Set the seed at 1, and then repeat the permutation 1,000 times to create a null distribution. What is the permutation derived p-value for our observation? N &lt;- 10 set.seed(1) nonsmokers &lt;- sample(bwt.nonsmoke,N) smokers &lt;- sample(bwt.smoke,N) obs &lt;- mean(smokers) - mean(nonsmokers) set.seed(1) res_list &lt;- replicate(1000, { dat &lt;- c(smokers,nonsmokers) shuffle &lt;- sample(dat) smokersstar &lt;- shuffle[1:N] nonsmokersstar &lt;- shuffle[(N+1):(2*N)] avgdiff &lt;- mean(smokersstar) - mean(nonsmokersstar) return(avgdiff) }) (sum(abs(res_list) &gt; abs(obs)) +1)/(length(res_list)+1) ## [1] 0.05294705 Due to the random numbers, the actual answer might differ. Question 2 Repeat the above exercise, but instead of the differences in mean, consider the differences in median obs &lt;- median(smokers) - median(nonsmokers). What is the permutation based p-value? N &lt;- 10 set.seed(1) nonsmokers &lt;- sample(bwt.nonsmoke,N) smokers &lt;- sample(bwt.smoke,N) obs &lt;- median(smokers) - median(nonsmokers) set.seed(1) res_list &lt;- replicate(1000, { dat &lt;- c(smokers,nonsmokers) shuffle &lt;- sample(dat) smokersstar &lt;- shuffle[1:N] nonsmokersstar &lt;- shuffle[(N+1):(2*N)] avgdiff &lt;- median(smokersstar) - median(nonsmokersstar) return(avgdiff) }) (sum(abs(res_list) &gt; abs(obs)) +1)/(length(res_list)+1) ## [1] 0.01798202 Due to the random numbers, the actual answer might differ. 2.25 Exercises d = read.csv(&#39;assoctest.csv&#39;) Question 1 This dataframe refects the allele status (either AA/Aa or aa) and the case/control status for 72 individuals. Compute the Chi-square test for the association of genotype with case/control status (using the table function and the chisq.test function). Examine the table to see if it looks enriched for association by eye. What is the X-squared statistic? tab &lt;- table(d) chisq.test(tab)$statistic ## X-squared ## 3.343653 Question 2 Compute Fisher’s exact test fisher.test for the same table. What is the p-value (two-tailed)? fisher.test(tab)$p.value ## [1] 0.05193834 "],
["exploratory-data-analysis.html", "Chapter 3 Exploratory Data Analysis 3.8 Exercises 3.11 Exercises", " Chapter 3 Exploratory Data Analysis Note: I have rephrased some parts of the questions for clarity. These changes are bolded. Due to the random numbers, the exact values of the answers, despite the same seeds, might differ. So please be mindful of that. First, upload necessary package(s). library(dplyr) # uplaods the function filter() and %&gt;% library(rafalib) # important for plotting with base R 3.8 Exercises Question 1 Given the above histogram, how many people are between the ages of 35 and 45? 6 people Question 2 The InsectSprays dataset is included in R. The dataset reports the counts of insects in agricultural experimental units treated with different insecticides. Make a boxplot and determine which insecticide appears to be most effective (has the lowest median). dat &lt;- split(InsectSprays$count, InsectSprays$spray) boxplot(dat) C has the lowest median and is, therefore, most effective. Question 3 Download the data and load them by typing load(skew.RData) into R. Use exploratory data analysis tools to determine which two columns are different from the rest. Which column has positive skew (a long tail to the right)? load(&#39;skew.RData&#39;) boxplot(dat) hist(dat[,4]) # Column 4 has a positive skew. Notice that boxplot function automatically splits each column of the dat (total 9 columns). Hence, there are 9 boxplots total, each of which has 1000 points; the dimension of dat is 1000 x 9 (dim(dat)). Negative skew refers to a longer or fatter tail on the left side of the distribution, while positive skew refers to a longer or fatter tail on the right. Question 4 Which column has negative skew (a long tail to the left)? hist(dat[,9]) # Column 9 has a negative skew. Question 5 Let’s consider a random sample of finishers from the New York City Marathon in 2002. This dataset can be found in the UsingR package. Load the library and then load the nym.2002 dataset. library(dplyr) data(nym.2002, package=&quot;UsingR&quot;) Use boxplots and histograms to compare the finishing times of males and females. Which of the following best describes the difference? data(nym.2002, package=&quot;UsingR&quot;) male &lt;- nym.2002 %&gt;% filter(gender == &#39;Male&#39;) female &lt;- nym.2002 %&gt;% filter(gender == &#39;Female&#39;) mypar(1,2) hist(female$time, xlim = c(100,600)) hist(male$time, xlim = c(100,600)) Both histograms have a similar distribution (skewed to the right). But the center of the histogram seems to be different. We can check this by calculating the absolute difference of the mean and median. abs(mean(male$time) - mean(female$time)) ## [1] 23.11574 abs(median(male$time) - median(female$time)) ## [1] 21.70833 There is a difference of around 21-23 minutes between males and females. So answer C seems to be appropriate: Males and females have similar right skewed distributions, with the former 20 minutes shifted to the left. Question 6 Use dplyr to create two new data frames: males and females, with the data for each gender. For males, what is the Pearson correlation between age and time to finish? plot(male$age, male$time, main = &#39;male&#39;) cor(male$age, male$time) ## [1] 0.2432273 Question 7 For females, what is the Pearson correlation between age and time to finish? plot(female$age, female$time, main = &#39;female&#39;) cor(female$age, female$time) ## [1] 0.2443156 Question 8 If we interpret these correlations without visualizing the data, we would conclude that the older we get, the slower we run marathons, regardless of gender. Look at scatterplots and boxplots of times stratified by age groups (20-24, 25-30, etc.). After examining the data, what is a more reasonable conclusion? groups_m &lt;- split(male$time, floor(male$age/5)*5) # 10-14, 15-19, etc groups_f &lt;- split(female$time, floor(female$age/5)*5) # 10-14, 15-19, etc mypar(1,2) boxplot(groups_m) boxplot(groups_f) This is a tricky question because the question asks you to stratify the data into groups. Stratification can be achieved via split function. To have each group a range of 5 (ex. 25-30), all the age numbers will have to be rounded up or down so that the resulting numbers will be divisible by 5. I rounded the numbers down by using the floor function. As a result, 40 represents the 40-44 age group. You can also use the ceiling function to stratify the data, which will then be rounded up. So, 45 represents 41-45 age group. In the example below, age of 42 is categorized using both floor and ceiling functions. floor(42/5)*5 ## [1] 40 ceiling(42/5)*5 ## [1] 45 The appropriate answer is A: Finish times are constant up until about our 40s, then we get slower. Question 9 When is it appropriate to use pie charts or donut charts? Never (answer choice D) Question 10 The use of pseudo-3D plots in the literature mostly adds: Confusion (answer choice D) 3.11 Exercises First load the data. data(ChickWeight) mypar() plot(ChickWeight$Time, ChickWeight$weight, col=ChickWeight$Diet) chick = reshape(ChickWeight, idvar=c(&quot;Chick&quot;,&quot;Diet&quot;), timevar=&quot;Time&quot;, direction=&quot;wide&quot;) chick = na.omit(chick) Question 1 Focus on the chick weights on day 4 (check the column names of chick and note the numbers). How much does the average of chick weights at day 4 increase if we add an outlier measurement of 3000 grams? Specifically, what is the average weight of the day 4 chicks, including the outlier chick, divided by the average of the weight of the day 4 chicks without the outlier. Hint: use c to add a number to a vector. chick_w4 &lt;- chick[,&#39;weight.4&#39;] chick_w4_add &lt;- append(chick_w4, 3000) # or use function c # chick_w4_add &lt;- c(chick_w4, 3000) chick_w4_add ## [1] 59 58 55 56 48 59 57 59 52 63 56 53 ## [13] 62 61 55 54 62 64 61 58 62 57 58 58 ## [25] 59 59 62 65 63 63 64 61 56 61 61 66 ## [37] 66 63 69 61 62 66 62 64 67 3000 mean(chick_w4_add) - mean(chick_w4) # Difference between with and without outlier ## [1] 63.90966 mean(chick_w4_add)/mean(chick_w4) # Ratio between with and without outlier ## [1] 2.062407 Question 2 In exercise 1, we saw how sensitive the mean is to outliers. Now let’s see what happens when we use the median instead of the mean. Compute the same ratio, but now using median instead of mean. Specifically, what is the median weight of the day 4 chicks, including the outlier chick, divided by the median of the weight of the day 4 chicks without the outlier. median(chick_w4_add) - median(chick_w4) # difference ## [1] 0 median(chick_w4_add)/median(chick_w4) # ratio ## [1] 1 Question 3 Now try the same thing with the sample standard deviation (the sd function in R). Add a chick with weight 3000 grams to the chick weights from day 4. How much does the standard deviation change? What’s the standard deviation with the outlier chick divided by the standard deviation without the outlier chick? sd(chick_w4_add) - sd(chick_w4) # difference ## [1] 429.1973 sd(chick_w4_add)/ sd(chick_w4) # ratio ## [1] 101.2859 Question 4 Compare the result above to the median absolute deviation in R, which is calculated with the mad function. Note that the mad is unaffected by the addition of a single outlier. The mad function in R includes the scaling factor 1.4826, such that mad and sd are very similar for a sample from a normal distribution. What’s the MAD with the outlier chick divided by the MAD without the outlier chick? mad(chick_w4_add) - mad(chick_w4) # difference ## [1] 0 mad(chick_w4_add)/ mad(chick_w4) # ratio ## [1] 1 Question 5 Our last question relates to how the Pearson correlation is affected by an outlier as compared to the Spearman correlation. The Pearson correlation between x and y is given in R by cor(x,y). The Spearman correlation is given by cor(x,y,method=\"spearman\"). Plot the weights of chicks from day 4 and day 21. We can see that there is some general trend, with the lower weight chicks on day 4 having low weight again on day 21, and likewise for the high weight chicks. Calculate the Pearson correlation of the weights of chicks from day 4 and day 21. Now calculate how much the Pearson correlation changes if we add a chick that weighs 3000 on day 4 and 3000 on day 21. Again, divide the Pearson correlation with the outlier chick over the Pearson correlation computed without the outliers. chick_w21 &lt;- chick[, &#39;weight.21&#39;] chick_w21 ## [1] 205 215 202 157 223 157 305 98 124 175 205 96 266 142 157 ## [16] 117 331 167 175 74 265 251 192 233 309 150 256 305 147 341 ## [31] 373 220 178 290 272 321 204 281 200 196 238 205 322 237 264 plot(chick_w4, chick_w21) cor(chick_w4,chick_w21) # correlation before ## [1] 0.4159499 chick_w21_add &lt;- append(chick_w21, 3000) cor(chick_w4_add, chick_w21_add) # correlation after outlier ## [1] 0.9861002 cor(chick_w4_add, chick_w21_add)/cor(chick_w4,chick_w21) # ratio between after and before ## [1] 2.370719 Question 6 Save the weights of the chicks on day 4 from diet 1 as a vector x. Save the weights of the chicks on day 4 from diet 4 as a vector y. Perform a t-test comparing x and y(in R the function t.test(x,y) will perform the test). Then perform a Wilcoxon test of x and y (in R the function wilcox.test(x,y) will perform the test). A warning will appear that an exact p-value cannot be calculated with ties, so an approximation is used, which is fine for our purposes. Perform a t-test of x and y, after adding a single chick of weight 200 grams to x (the diet 1 chicks). What is the p-value from this test? The p-value of a test is available with the following code: t.test(x,y)$p.value x &lt;- chick %&gt;% filter(Diet == 1) x &lt;- x[,&#39;weight.4&#39;] y &lt;- chick %&gt;% filter(Diet == 4) y &lt;- y[,&#39;weight.4&#39;] t.test(x,y)$p.value # t.test result with no outlier ## [1] 7.320259e-06 wilcox.test(x,y)$p.value # wilcox result with no outlier ## Warning in wilcox.test.default(x, y): cannot compute exact p- ## value with ties ## [1] 0.0002011939 x_add &lt;- c(x,200) # outlier added t.test(x_add,y)$p.value # t-test after outlier ## [1] 0.9380347 Question 7 Do the same for the Wilcoxon test. The Wilcoxon test is robust to the outlier. In addition, it has fewer assumptions than the t-test on the distribution of the underlying data. wilcox.test(x_add,y)$p.value # even with outlier, p-value is not perturbed ## Warning in wilcox.test.default(x_add, y): cannot compute exact p- ## value with ties ## [1] 0.0009840921 Question 8 We will now investigate a possible downside to the Wilcoxon-Mann-Whitney test statistic. Using the following code to make three boxplots, showing the true Diet 1 vs 4 weights, and then two altered versions: one with an additional difference of 10 grams and one with an additional difference of 100 grams. Use the x and y as defined above, NOT the ones with the added outlier. library(rafalib) mypar(1,3) boxplot(x,y) boxplot(x,y+10) boxplot(x,y+100) What is the difference in t-test statistic (obtained by t.test(x,y)$statistic) between adding 10 and adding 100 to all the values in the group y? Take the the t-test statistic with x and y+10 and subtract the t-test statistic with x and y+100. The value should be positive. t.test(x,y+10)$statistic - t.test(x,y+100)$statistic ## t ## 67.75097 Question 9 Examine the Wilcoxon test statistic for x and y+10 and for x and y+100. Because the Wilcoxon works on ranks, once the two groups show complete separation, that is, all points from group y are above all points from group x, the statistic will not change, regardless of how large the difference grows. Likewise, the p-value has a minimum value, regardless of how far apart the groups are. This means that the Wilcoxon test can be considered less powerful than the t-test in certain contexts. In fact, for small sample sizes, the p-value can’t be very small, even when the difference is very large. What is the p-value if we compare c(1,2,3) to c(4,5,6) using a Wilcoxon test? wilcox.test(x,y+10)$p.value ## Warning in wilcox.test.default(x, y + 10): cannot compute exact ## p-value with ties ## [1] 5.032073e-05 wilcox.test(x,y+100)$p.value ## Warning in wilcox.test.default(x, y + 100): cannot compute exact ## p-value with ties ## [1] 5.032073e-05 wilcox.test(c(1,2,3),c(4,5,6))$p.value # Answer ## [1] 0.1 Question 10 What is the p-value if we compare c(1,2,3) to c(400,500,600) using a Wilcoxon test? wilcox.test(c(1,2,3),c(400,500,600))$p.value ## [1] 0.1 "],
["matrix-algebra.html", "Chapter 4 Matrix Algebra 4.2 Exercises 4.6 Exercises 4.8 Exercises 4.10 Exercises", " Chapter 4 Matrix Algebra Note: I have rephrased some parts of the questions for clarity. These changes are bolded. Due to the random numbers, the exact values of the answers, despite the same seeds, might differ. So please be mindful of that. First, upload necessary package(s). library(dplyr) # uplaods the function filter() and %&gt;% library(rafalib) # important for plotting with base R 4.2 Exercises #install.packages(&#39;UsingR&#39;) data(&#39;father.son&#39;, package = &#39;UsingR&#39;) Question 1 What is the average height of the sons (don’t round off)? y &lt;- father.son$sheight # son x &lt;- father.son$fheight # father mean(y) ## [1] 68.68407 Question 2 One of the defining features of regression is that we stratify one variable based on others. In statistics, we use the verb ‘condition.’ For exmaple,, the linear model for son and father heights answers the question: how tall do I expect a son to be if I condition on his father being \\(x\\) inches? The regression line answers this question for any \\(x\\). Using the father.son dataset described above, we want to know the expected height of sons, if we condition on the father being 71 inches. Create a list of son heights for sons that have fathers with heights of 71 inches, rounding to the nearest inch. What is the mean of the son heights for fathers that have a height of 71 inches (don’t round off your answer)? Hint: use the function round on the fathers’ heights. groups &lt;- split(y, round(x)) mean(groups[&#39;71&#39;] %&gt;% unlist()) ## [1] 70.54082 Question 3 of the following cannot be written as a linear model? The answer is C: \\(Y = a + b^t + \\epsilon\\). This is because the variable \\(t\\) is an exponent unlike all the other answer choices. Question 4 Suppose you model the relationship between weight and height across individuals with a linear model. You assume that the height of individuals for a fixed weight \\(x\\) follows a linear model \\(Y = a + bx + \\epsilon\\). Which of the following do you feel best describes what \\(\\epsilon\\) represents? The answer is D: Between individual variability: people of the same height vary in their weight. Let’s look at each answer choice. Let’s first think \\(Y\\) as son’s height and \\(x\\) as father’s height. So in this linear model, our goal is to predict son’s height based on father’s height. Choice A (Measurement error: scales are not perfect) seems not wrong. However, if the father’s height is 71 inches, can we gurantee that the son’s height is a certain number with a small measurement variability? This is not true because the son’s range of height can still be wide even if the father’s height is 71 inches. In fact, siblings can have very different heights even if their biological parents are identical. Since choice A only describes the \\(\\epsilon\\) as measurement variability, the description seems inadequate. This explanation also applies to Choice B (Within individual random fluctuations: you don’t weigh the same in the morning as in the afternoon) and C (Round off error introduced by the computer). Therefore, choice D seems to be most appropriate. 4.6 Exercises Question 1 In R we have vectors and matrices. You can create your own vectors with the function c. c(1,5,3,4) ## [1] 1 5 3 4 They are also the output of many functions such as: rnorm(10) ## [1] -0.8043316 -1.0565257 -1.0353958 -1.1855604 -0.5004395 ## [6] -0.5249887 -0.3024330 0.4719681 -0.2483839 1.2593180 You can turn vectors into matrcies using functions such as rbind, cbind, or matrix. Create the matrix from the vector 1:1000 like this: X = matrix(1:1000,100,10) What is the entry in row 25, column 3? X[25,3] ## [1] 225 Question 2 Using the function cbind, create a 10 x 5 matrix with first column x=1:10. Then add 2*x, 3*x, 4*x and 5*x to columns 2 through 5. What is the sum of the elements of the 7th row? first_column &lt;- 1:10 y &lt;- cbind(x1=first_column, x2=first_column*2, x3=first_column*3, x4=first_column*4, x5=first_column*5) sum(y[7,]) ## [1] 105 Question 3 Which of the following creates a matrix with multiples of 3 in the third column? matrix(1:60,20,3) # choice A ## [,1] [,2] [,3] ## [1,] 1 21 41 ## [2,] 2 22 42 ## [3,] 3 23 43 ## [4,] 4 24 44 ## [5,] 5 25 45 ## [6,] 6 26 46 ## [7,] 7 27 47 ## [8,] 8 28 48 ## [9,] 9 29 49 ## [10,] 10 30 50 ## [11,] 11 31 51 ## [12,] 12 32 52 ## [13,] 13 33 53 ## [14,] 14 34 54 ## [15,] 15 35 55 ## [16,] 16 36 56 ## [17,] 17 37 57 ## [18,] 18 38 58 ## [19,] 19 39 59 ## [20,] 20 40 60 matrix(1:60,20,3, byrow=T) # choice B ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 4 5 6 ## [3,] 7 8 9 ## [4,] 10 11 12 ## [5,] 13 14 15 ## [6,] 16 17 18 ## [7,] 19 20 21 ## [8,] 22 23 24 ## [9,] 25 26 27 ## [10,] 28 29 30 ## [11,] 31 32 33 ## [12,] 34 35 36 ## [13,] 37 38 39 ## [14,] 40 41 42 ## [15,] 43 44 45 ## [16,] 46 47 48 ## [17,] 49 50 51 ## [18,] 52 53 54 ## [19,] 55 56 57 ## [20,] 58 59 60 x = 11:20; rbind(x,2*x,3*x) # choice C ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## x 11 12 13 14 15 16 17 18 19 20 ## 22 24 26 28 30 32 34 36 38 40 ## 33 36 39 42 45 48 51 54 57 60 x = 1:40; matrix(3*x,20,2) # choice D ## [,1] [,2] ## [1,] 3 63 ## [2,] 6 66 ## [3,] 9 69 ## [4,] 12 72 ## [5,] 15 75 ## [6,] 18 78 ## [7,] 21 81 ## [8,] 24 84 ## [9,] 27 87 ## [10,] 30 90 ## [11,] 33 93 ## [12,] 36 96 ## [13,] 39 99 ## [14,] 42 102 ## [15,] 45 105 ## [16,] 48 108 ## [17,] 51 111 ## [18,] 54 114 ## [19,] 57 117 ## [20,] 60 120 The answer is B. 4.8 Exercises Question 1 Suppose \\(X\\) is a matrix in R. Which of the following is not equivalent to \\(X\\)? head(t(t(X))) # A ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 1 101 201 301 401 501 601 701 801 901 ## [2,] 2 102 202 302 402 502 602 702 802 902 ## [3,] 3 103 203 303 403 503 603 703 803 903 ## [4,] 4 104 204 304 404 504 604 704 804 904 ## [5,] 5 105 205 305 405 505 605 705 805 905 ## [6,] 6 106 206 306 406 506 606 706 806 906 head(X %*% matrix(1,ncol(X))) # B ## [,1] ## [1,] 4510 ## [2,] 4520 ## [3,] 4530 ## [4,] 4540 ## [5,] 4550 ## [6,] 4560 head(X*1) # C ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 1 101 201 301 401 501 601 701 801 901 ## [2,] 2 102 202 302 402 502 602 702 802 902 ## [3,] 3 103 203 303 403 503 603 703 803 903 ## [4,] 4 104 204 304 404 504 604 704 804 904 ## [5,] 5 105 205 305 405 505 605 705 805 905 ## [6,] 6 106 206 306 406 506 606 706 806 906 head(X %*% diag(ncol(X))) # D ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 1 101 201 301 401 501 601 701 801 901 ## [2,] 2 102 202 302 402 502 602 702 802 902 ## [3,] 3 103 203 303 403 503 603 703 803 903 ## [4,] 4 104 204 304 404 504 604 704 804 904 ## [5,] 5 105 205 305 405 505 605 705 805 905 ## [6,] 6 106 206 306 406 506 606 706 806 906 The answer is B. In choice A, the trasnposed matrix \\(X\\) gets transposed again, thereby returning to its original matrix \\(X\\). In choice B, the matrix \\(X\\) gets multiplied by 1, which is a scalar. So it will not be changed. In choice D, \\(X\\) gets multiplied by an identity matrix, so \\(X\\) does not change even after the matrix multiplication. Therefore, the answer is B. Question 2 Solve the following system of equations using R: \\[ \\begin{align*} 3a + 4b - 5c + d=10\\\\ 2a + 2b + 2c - d = 5\\\\ a - b + 5c - 5d = 7 \\\\ 5a + 5d = 4 \\end{align*} \\] What is the solution for \\(c\\)? X &lt;- matrix(c(3,4,-5,1,2,2,2,-1,1,-1,5,-5,5,0,0,1),4,4,byrow=T) ans &lt;- solve(X) %*% matrix(c(10,5,7,4),4,1) ans[3] ## [1] -0.8849558 Question 3 Load the following two matrices into R: a &lt;- matrix(1:12, nrow=4) b &lt;- matrix(1:15, nrow=3) What is the value in the 3rd row and the 2nd column of the matrix product of a and b? c &lt;- a %*% b c[3,2] ## [1] 113 Question 4 Multiply the 3rd row of a with the 2nd column of b, using the element-wise vector multiplication with *. What is the sum of the elements in the resulting vector? sum(a[3,] * b[,2]) ## [1] 113 4.10 Exercises Question 1 Suppose we are analyzing a set of 4 samples. The first two samples are from a treatment group A and the second two samples are from a treatment group B. This design can be represented with a model matrix like so: X &lt;- matrix(c(1,1,1,1,0,0,1,1),nrow=4) rownames(X) &lt;- c(&#39;a&#39;,&#39;a&#39;,&#39;b&#39;,&#39;b&#39;) X ## [,1] [,2] ## a 1 0 ## a 1 0 ## b 1 1 ## b 1 1 Suppose that the fitted parameters for a linear model give us: beta &lt;- c(5,2) Use the matrix multiplication operator, %*%, in R to answer the following questions: What is the fitted value for the A samples? (The fitted Y values.) X &lt;- matrix(c(1,1,1,1,0,0,1,1),nrow=4) rownames(X) &lt;- c(&#39;a&#39;,&#39;a&#39;,&#39;b&#39;,&#39;b&#39;) #beta &lt;- c(5,2) beta &lt;- matrix(c(5,2),nrow =2, ncol=1) # matrix form of the vector beta X[1:2,] %*% beta ## [,1] ## a 5 ## a 5 When I perform matrix multiplication in R %*%, I usually make sure that all my vectors are converted into matrix. In this case, I rewrote the beta variable in the function of matrix. However, this is not necessary. The vector form of beta beta &lt;- c(5,2) works well too. Question 2 What is the fitted value for the B samples? (The fitted Y values.) X[3:4,] %*% beta ## [,1] ## b 7 ## b 7 Question 3 Suppose now we are comparing two treatments B and C to a control group A, each with two samples. This design can be represented with a model matrix like so: X &lt;- matrix(c(1,1,1,1,1,1,0,0,1,1,0,0,0,0,0,0,1,1),nrow=6) rownames(X) &lt;- c(&quot;a&quot;,&quot;a&quot;,&quot;b&quot;,&quot;b&quot;,&quot;c&quot;,&quot;c&quot;) X ## [,1] [,2] [,3] ## a 1 0 0 ## a 1 0 0 ## b 1 1 0 ## b 1 1 0 ## c 1 0 1 ## c 1 0 1 Suppose that the fitted values for the linear model are given by: beta &lt;- c(10,3,-3) What is the fitted values for the B sample? beta &lt;- matrix(c(10,3,-3),nrow = 3) X[3:4,] %*% beta ## [,1] ## b 13 ## b 13 Question 4 What is the fitted values for the C sample? X[5:6,] %*% beta ## [,1] ## c 7 ## c 7 "],
["linear-models.html", "Chapter 5 Linear Models 5.1 Exercises 5.3 Exercises 5.5 Exercises 5.7 Exercises 5.11 Exercises 5.15 Exercises", " Chapter 5 Linear Models Note: I have rephrased some parts of the questions for clarity. These changes are bolded. Due to the random numbers, the exact values of the answers, despite the same seeds, might differ. So please be mindful of that. First, upload necessary package(s). library(dplyr) # uplaods the function filter() and %&gt;% library(rafalib) # important for plotting with base R library(contrast) ## Warning: package &#39;contrast&#39; was built under R version 3.5.3 library(Matrix) 5.1 Exercises Question 1 We have shown how to find the least squares estimates with matrix algebra. These estimates are random variables as they are linear combinations of the data. For these estimates to be useful, we also need to compute the standard errors. Here we review standard errors in the context of linear models. To see this, we can run a Monte Carlo simulation to imitate the collection of falling object data. Specifically, we will generate the data repeatedly and compute the estimate for the quadratic term each time. g = 9.8 h0 = 56.67 v0 = 0 n = 25 tt = seq(0,3.4,len=n) y = h0 + v0 *tt - 0.5* g*tt^2 + rnorm(n,sd=1) Now we act as if we didn’t know \\(h0\\), \\(v0\\) and \\(-0.5*g\\) and use regression to estimate these. We can rewrite the model as \\(y = \\beta_0 + \\beta_1t + \\beta_2t^2 + \\epsilon\\) and obtain the LSE we have used in this class. Note that \\(g = -2\\beta_2\\). To obtain the LSE in R we could write: X = cbind(1,tt,tt^2) A = solve(crossprod(X))%*%t(X) Given how we have defined A, which of the following is the LSE of \\(g\\), the accerleration due to gravity? Y = matrix(y,nrow=length(y), ncol = 1) # convert vector y into matrix Y betahat &lt;- solve(crossprod(X)) %*% t(X) %*%Y betahat &lt;- A %*% Y # both ways work fine betahat[[3]] * -2 # beta2 * -2 = gravity ## [1] 9.279798 # this is equal to -2 * (A %*% Y)[3] ## [1] 9.279798 The answer is C. Answer A is wrong because 9.8 is not an estimate; it is the exact value we are looking for. Due to measurement error rnorm(n, sd=1) that is generated in y, we will never achieve 9.8. Answer B is wrong because this gives three coefficients (intercept h0, v0 and -0.5g). Answer D is wrong because A is created solely from the model matrix X, not also from the data y. Question 2 In the lines of code above, the function rnorm introduced randomness. This means that each time the lines of code above are repeated, the estimate of g will be different. Use the code above in conjunction with the function replicate to generate 100,000 Monte Carlo simulated datasets. For each dataset, compute an estimate of g. (Remember to multiply by -2.) What is the standard error of this estimate? set.seed(1) gravity_list &lt;- replicate(100000, { y = h0 + v0 *tt - 0.5* g*tt^2 + rnorm(n,sd=1) Y = matrix(y,nrow=length(y), ncol = 1) betahat &lt;- solve(crossprod(X)) %*% t(X) %*%Y third_beta &lt;- betahat[[3]] * -2 return(third_beta) }) popsd(gravity_list) ## [1] 0.4297449 Function popsd, instead of sd, is used because we are not dealing with a sample of coefficients. sd adjusts for the bias in a sample by using denominator n-1 rather than n. In this case, there is no reason to adjust for the bias because we are directly interested in measuring the spread of the distribution of third_beta. Standard error of a random variable is the standard deviation of the distribution; gravity_list captures the distribution of third_beta. Therefore we compute standard deviation. Question 3 In the father and son height examples, we have randomness because we have a random sample of father and son pairs. For the sake of illustration, let’s assume that this is the entire population: library(UsingR) ## Warning: package &#39;UsingR&#39; was built under R version 3.5.3 ## Loading required package: MASS ## ## Attaching package: &#39;MASS&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## select ## Loading required package: HistData ## Warning: package &#39;HistData&#39; was built under R version 3.5.3 ## Loading required package: Hmisc ## Warning: package &#39;Hmisc&#39; was built under R version 3.5.3 ## Loading required package: lattice ## Loading required package: survival ## Warning: package &#39;survival&#39; was built under R version 3.5.3 ## Loading required package: Formula ## Warning: package &#39;Formula&#39; was built under R version 3.5.2 ## Loading required package: ggplot2 ## ## Attaching package: &#39;Hmisc&#39; ## The following objects are masked from &#39;package:dplyr&#39;: ## ## src, summarize ## The following objects are masked from &#39;package:base&#39;: ## ## format.pval, units ## ## Attaching package: &#39;UsingR&#39; ## The following object is masked _by_ &#39;.GlobalEnv&#39;: ## ## babies ## The following object is masked from &#39;package:survival&#39;: ## ## cancer x = father.son$fheight y = father.son$sheight n = length(y) Now let’s run a Monte Carlo simulation in which we take a sample of size 50 over and over again. Here is how we obtain one sample: N = 50 index = sample(n,N) sampledat = father.son[index,] x = sampledat$fheight y = sampledat$sheight betahat = lm(y~x)$coef Use the function replicate to take 10,000 samples. What is the standard error of the slope estimate? That is, calculate the standard deviation of the estimate from the observed values obtained from many random samples. x = father.son$fheight y = father.son$sheight n = length(y) N = 50 set.seed(1) output &lt;- replicate(10000, { index = sample(n,N) sampledat = father.son[index,] x = sampledat$fheight y = sampledat$sheight betahat = lm(y~x)$coef return(betahat[[2]]) }) popsd(output) ## [1] 0.1243209 Question 4 Which of the following is closest to the covariance between father heights and son heights? #x = father.son$fheight #y = father.son$sheight mean((y - mean(y))*(x-mean(x))) # closest to 4 ## [1] 3.869739 5.3 Exercises Question 1 Given the factors we have defined above and without defining any new ones, which of the following R formula will produce a design matrix (model matrix) that lets us analyze the effect of condition, controlling for the different days? day &lt;- c(&#39;A&#39;,&#39;A&#39;,&#39;B&#39;,&#39;B&#39;,&#39;C&#39;,&#39;C&#39;) condition &lt;- c(&#39;control&#39;,&#39;treatment&#39;,&#39;control&#39;,&#39;treatment&#39;,&#39;control&#39;,&#39;treatment&#39;) model.matrix(~day+condition) # answer is A ## (Intercept) dayB dayC conditiontreatment ## 1 1 0 0 0 ## 2 1 0 0 1 ## 3 1 1 0 0 ## 4 1 1 0 1 ## 5 1 0 1 0 ## 6 1 0 1 1 ## attr(,&quot;assign&quot;) ## [1] 0 1 1 2 ## attr(,&quot;contrasts&quot;) ## attr(,&quot;contrasts&quot;)$day ## [1] &quot;contr.treatment&quot; ## ## attr(,&quot;contrasts&quot;)$condition ## [1] &quot;contr.treatment&quot; 5.5 Exercises Question 1 You can make a design matrix X for a two group comparison, either using model.matrix or simply with: #X &lt;- cbind(rep(1,Nx + Ny),rep(c(0,1),c(Nx, Ny))) In order to compare two groups, where the first group has Nx=5 samples and the second group has Ny=7 samples, what is the element in the 1st row and 1st column of \\(X^TX\\)? Nx &lt;- 5 Ny &lt;- 7 X &lt;- cbind(rep(1,Nx+Ny), rep(c(0,1),c(Nx,Ny))) crossprod(X)[1,1] # this is equal to Nx + Ny ## [1] 12 Question 2 The other entries of \\(X^TX\\) are all the same. What is the number? crossprod(X) # 7, this is equal to Ny ## [,1] [,2] ## [1,] 12 7 ## [2,] 7 7 5.7 Exercises library(UsingR) N &lt;- 50 set.seed(1) index &lt;- sample(n,N) sampledat &lt;- father.son[index,] x &lt;- sampledat$fheight y &lt;- sampledat$sheight betahat &lt;- lm(y~x)$coef Question 1 The fitted values \\(\\hat{Y}\\) from a linear model can be obtained with: fit &lt;- lm(y~x) fit$fitted.values ## 1 2 3 4 5 6 7 ## 70.62707 70.36129 70.86093 68.73019 65.59181 70.55285 70.21256 ## 8 9 10 11 12 13 14 ## 68.62521 67.06729 69.64913 69.09958 71.70621 68.31598 70.57027 ## 15 16 17 18 19 20 21 ## 70.39537 70.39613 68.73977 68.98874 71.47021 72.03615 69.55975 ## 22 23 24 25 26 27 28 ## 68.15895 66.63557 71.53651 69.57083 69.71050 67.14263 70.99719 ## 29 30 31 32 33 34 35 ## 67.11046 69.04901 66.65243 67.82895 68.24209 70.70156 65.50431 ## 36 37 38 39 40 41 42 ## 67.36000 69.30065 67.94424 66.35150 71.40489 71.64301 66.81654 ## 43 44 45 46 47 48 49 ## 69.22900 69.11769 69.21793 69.69519 67.00674 68.67869 67.40752 ## 50 ## 69.28800 What is the sum of the squared residuals, where residuals are given by \\(r_i = Y_i - \\hat{Y}_i\\)? sum((y -fit$fitted.values)^2) ## [1] 256.2152 resid = y -fit$fitted.values # residual sum(resid^2) ## [1] 256.2152 In the four questions, we will calculate the standard error of the least square estimates (i.e., coefficients / beta hats from the linear model). This can easily be achieved with function lm(), but we will explore what happens within lm(). It is important to recall that \\(\\hat{Y}_i\\) is the fitted values from the model \\(X\\hat{\\beta}\\), and that \\(Y\\) is the actual data. A difference between these two is the residual. Question 2 Our estimate of \\(\\sigma^2\\) will be the sum of squared residuals divided by \\(N-p\\), the sample size minus the number of terms in the model. Since we have a sample of 50 and 2 terms in the model (an intercept and a slope), our estimate of \\(\\sigma^2\\) will be the sum of squared residuals divided by 48. Use the answer from Question 1 to provide an estimate of \\(\\sigma^2\\). s2 &lt;- sum(resid^2)/48 s2 ## [1] 5.337816 So what exactly is \\(\\sigma^2\\)? To understand it, we need to revisit a typical linear model \\(Y_i = \\beta_0 + \\beta_1X_i + \\epsilon_i\\), where _0 is the intercept. When you are estimating \\(Y_i\\) from a model, you can get variance for \\(Y_i\\). However, since the parameters (\\(\\beta_0\\) and \\(\\beta_1\\)) are assumed to be fixed (known values), the variance of the \\(Y_i\\) only comes from the \\(\\epsilon_i\\). Therefore \\(\\sigma^2\\) is basically the variance of \\(\\epsilon\\). Question 3 Form the design matrix \\(X\\) (Note: use a capital X). This can be done by combining a column of 1’s with a column containing x, the fathers’ heights. N &lt;- 50 X &lt;- cbind(rep(1,N),x) Now calculate \\((X^TX)^{-1}\\). Use the solve function for the inverse and t for the transpose. What is the element in the first row, first column? X &lt;- model.matrix(~x) solve(crossprod(X))[1,1] ## [1] 11.30275 Remember that crossprod(X) is equivalent to t(X) %*% X. Question 4 Now we are one step away from the standard error of \\(\\hat{\\beta}\\). Take the diagonals from the \\((X^TX)^{-1}\\) matrix above, using the diag function. Multiply our estmate of \\(\\sigma^2\\) and the diagonals of this matrix. This is the estimated variance of \\(\\hat{\\beta}\\), so take the square root of this. You should end up two numbers: the standard error for the intercept and the standard error for the slope. What is the standard error for the slope? sqrt(diag(solve(crossprod(X))) * s2)[2] ## x ## 0.1141966 Although the questions are relatively straightforward, the math derivation is not. Do not worry if you do not understand the derivation. The only thing that matters is that we have just computed the standard error of a coefficient in linear regression. And this can all be done with function lm. 5.11 Exercises Suppose we have an experiment with two species A and B, and two conditions, control and treated. species &lt;- factor(c(&quot;A&quot;,&quot;A&quot;,&quot;B&quot;,&quot;B&quot;)) condition &lt;- factor(c(&quot;control&quot;,&quot;treated&quot;,&quot;control&quot;,&quot;treated&quot;)) We will use the formula of ~ species + condition to create the model matrix: model.matrix(~species + condition) Question 1 Suppose we want to build a contrast of coefficients for the above experimental design. You can either figure this question out by looking at the design matrix, or by using the contrast function from the contrast library with random numbers for y. The contrast vector will be returned as contrast(...)$X. What should the contrast vector be, to obtain the difference between the species B control group and the species A treatment group (species B control - species A treatment)? Assume that the coeffcients (columns of design matrix) are: Intercept, speciesB, condition-treated. fit &lt;- lm(rnorm(4) ~ species + condition) table(species,condition) # just like in the species vector, there are four units total. ## condition ## species control treated ## A 1 1 ## B 1 1 etc &lt;- contrast(fit, list(species =&#39;B&#39;,condition=&#39;control&#39;), list(species =&#39;A&#39;,condition=&#39;treated&#39;)) etc$X ## (Intercept) speciesB conditiontreated ## 1 0 1 -1 ## attr(,&quot;assign&quot;) ## [1] 0 1 2 ## attr(,&quot;contrasts&quot;) ## attr(,&quot;contrasts&quot;)$species ## [1] &quot;contr.treatment&quot; ## ## attr(,&quot;contrasts&quot;)$condition ## [1] &quot;contr.treatment&quot; I made a model matrix by using rnorm(4), which generates four random numbers (mean=0, sd=1). Then I performed a contrast between species B control and species A treatment groups using the contrast function. I stored the results in etc, which shows that the answer is D (0,1,-1). Question 2 Use the Rmd script to load the spider dataset. Suppose we build a model using two variables: ~ type + leg. What is the t-statistic for the contrast of leg pair L4 vs. leg pair L2? spider &lt;- read.csv(&quot;spider_wolff_gorb_2013.csv&quot;, skip=1) fit &lt;- lm(friction~type+leg, data = spider) res &lt;- contrast(fit, list(leg =&#39;L4&#39;,type = &#39;pull&#39;), list(leg = &#39;L2&#39;,type=&#39;pull&#39;)) res$testStat ## 1 ## 2.451974 Question 3 X &lt;- model.matrix(~ type + leg, data=spider) Sigma.hat &lt;- sum(fit$residuals^2)/(nrow(X) - ncol(X)) * solve(t(X) %*% X) Using the estimate \\(\\Sigma\\) (estimated covariance matrix), what is your estimate of \\(cov(\\hat{\\beta}_{L4},\\hat{\\beta}_{L2})\\)? Our contrast matrix for the desired comparison is: C &lt;- matrix(c(0,0,-1,0,1),1,5) Sigma.hat &lt;- sum(fit$residuals^2)/(nrow(X)-ncol(X)) * solve(t(X)%*%X) # covariance matrix Sigma.hat ## (Intercept) typepush legL2 ## (Intercept) 0.0007929832 -3.081306e-04 -0.0006389179 ## typepush -0.0003081306 6.162612e-04 0.0000000000 ## legL2 -0.0006389179 -6.439411e-20 0.0020871318 ## legL3 -0.0006389179 -6.439411e-20 0.0006389179 ## legL4 -0.0006389179 -1.191291e-19 0.0006389179 ## legL3 legL4 ## (Intercept) -0.0006389179 -0.0006389179 ## typepush 0.0000000000 0.0000000000 ## legL2 0.0006389179 0.0006389179 ## legL3 0.0010566719 0.0006389179 ## legL4 0.0006389179 0.0011819981 The answer is 0.0006389179. It is important to know that sqrt(diag(Sigma.hat)) gives standard error of the least square estimates. Question 4 Suppose that we notice that the within-group variances for the groups with smaller frictional coeffcients are generally smaller, and so we try to apply a transformation to the frictional coeffcients to make the within-group variances more constant. Add a new variable log2friction to the spider dataframe: spider$log2friction &lt;- log2(spider$friction) The Y values now look like: boxplot(log2friction ~ type*leg, data=spider) Run a linear model of log2friction with type, leg and interactions between type and leg. What is the t-statistic for the interaction of type push and leg L4? If this t-statistic is sufficiently large, we would reject the null hypothesis that the push vs. pull effect on log2(friction) is the same in L4 as in L1. logfit &lt;- lm(log2friction~type+leg+type:leg, data = spider) summary(logfit)[[4]] # t-statistic of typepush:legL4 = -3.689 ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.1682816 0.06613097 -2.5446712 1.148701e-02 ## typepush -1.2065650 0.09352331 -12.9012220 4.472641e-30 ## legL2 0.3468125 0.11952459 2.9015992 4.014075e-03 ## legL3 0.4899946 0.08504571 5.7615441 2.237221e-08 ## legL4 0.6466753 0.08994784 7.1894475 6.199475e-12 ## typepush:legL2 0.0996718 0.16903330 0.5896578 5.559060e-01 ## typepush:legL3 -0.5407473 0.12027280 -4.4960067 1.023073e-05 ## typepush:legL4 -0.4692035 0.12720545 -3.6885485 2.719589e-04 Question 5 Using the same analysis of log2 transformed data, what is the F-value for all of the type:leg interaction terms in an ANOVA? If this value is sufficiently large, we would reject the null hypothesis that the push vs. pull effect on log2(friction) is the same for all leg pairs. anova(logfit) # F-value of type:leg: 10.701 ## Analysis of Variance Table ## ## Response: log2friction ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## type 1 164.709 164.709 1107.714 &lt; 2.2e-16 *** ## leg 3 7.065 2.355 15.838 1.589e-09 *** ## type:leg 3 4.774 1.591 10.701 1.130e-06 *** ## Residuals 274 40.742 0.149 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 5.15 Exercises Question 1 Consider these design matrices: \\[ \\, A = \\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0\\\\ 1 &amp; 0 &amp; 0 &amp; 0\\\\ 1 &amp; 1 &amp; 1 &amp; 0\\\\ 1 &amp; 1 &amp; 0 &amp; 1\\\\ \\end{pmatrix} \\ B = \\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 1\\\\ 1 &amp; 0 &amp; 1 &amp; 1\\\\ 1 &amp; 1 &amp; 0 &amp; 0\\\\ 1 &amp; 1 &amp; 1 &amp; 0\\\\ \\end{pmatrix} \\ C = \\begin{pmatrix} 1 &amp; 0 &amp; 0\\\\ 1 &amp; 1 &amp; 2\\\\ 1 &amp; 2 &amp; 4\\\\ 1 &amp; 3 &amp; 6\\\\ \\end{pmatrix} \\] \\[ \\, D = \\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\\\ 1 &amp; 1 &amp; 0 &amp; 1 &amp; 0\\\\ 1 &amp; 1 &amp; 0 &amp; 1 &amp; 1\\\\ 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0\\\\ 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1\\\\ \\end{pmatrix} \\ E = \\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0\\\\ 1 &amp; 0 &amp; 1 &amp; 0\\\\ 1 &amp; 1 &amp; 0 &amp; 0\\\\ 1 &amp; 1 &amp; 1 &amp; 1\\\\ \\end{pmatrix} \\ F = \\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 1\\\\ 1 &amp; 0 &amp; 0 &amp; 1\\\\ 1 &amp; 0 &amp; 1 &amp; 1\\\\ 1 &amp; 1 &amp; 0 &amp; 0\\\\ 1 &amp; 1 &amp; 0 &amp; 0\\\\ 1 &amp; 1 &amp; 1 &amp; 0\\\\ \\end{pmatrix} \\] Which of the above design matrices does NOT have the problem of collinearity? The answer is E. Collinearity exists when a column within the matrix is a linear combination of other columns in the same matrix. If a model matrix has collinearity, then it has a confound, thereby becoming problematic. In answer A, the second column is a linear combination of the third and fourth columns. In answer B, the first column is a linear combination of the second and fourth columns. In answer C, the third column is a multiple of the second column by a factor of 2. In answer D, the fourth column is a linear combination of the second and third columns. In answer F, the first column is a linear combination of the second and fourth columns. Question 2 sex &lt;- factor(rep(c(&quot;female&quot;,&quot;male&quot;),each=4)) trt &lt;- factor(c(&quot;A&quot;,&quot;A&quot;,&quot;B&quot;,&quot;B&quot;,&quot;C&quot;,&quot;C&quot;,&quot;D&quot;,&quot;D&quot;)) X &lt;- model.matrix( ~ sex + trt) qr(X)$rank ## [1] 4 Y &lt;- 1:8 makeYstar &lt;- function(a,b) Y - X[,2] * a - X[,5] * b fitTheRest &lt;- function(a,b) { Ystar &lt;- makeYstar(a,b) Xrest &lt;- X[,-c(2,5)] betarest &lt;- solve(t(Xrest) %*% Xrest) %*% t(Xrest) %*% Ystar residuals &lt;- Ystar - Xrest %*% betarest sum(residuals^2) } What is the sum of squared residuals when the male coefficient is 1 and D coefficient is 2, and the other coefficients are fit using the linear model solution? fitTheRest(1,2) ## [1] 11 Xrest refers to the model matrix that does not have \\(\\beta_{male}\\) and \\(\\beta_D\\). In this question, these two coefficients are fixed. Therefore, Xrest is used as a model matrix to compute least square estimates for the other three coefficients in X &lt;- model.matrix( ~ sex + trt).Try to recreate the custom function fitTheRest on your own. Question 3 We can apply our function fitTheRest to a grid of values for female and \\(\\beta_D\\), using the outer function in R. outer takes three arguments: a grid of values for the first argument, a grid of values for the second argument, and finally a function which takes two arguments. Try it out: outer(1:3,1:3,&#39;*&#39;) ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 2 4 6 ## [3,] 3 6 9 We can run fitTheRest on a grid of values, using the following code (the Vectorize is necessary as outer requires only vectorized functions) outer(-2:8,-2:8,Vectorize(fitTheRest)) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] ## [1,] 102 83 66 51 38 27 18 11 6 3 2 ## [2,] 83 66 51 38 27 18 11 6 3 2 3 ## [3,] 66 51 38 27 18 11 6 3 2 3 6 ## [4,] 51 38 27 18 11 6 3 2 3 6 11 ## [5,] 38 27 18 11 6 3 2 3 6 11 18 ## [6,] 27 18 11 6 3 2 3 6 11 18 27 ## [7,] 18 11 6 3 2 3 6 11 18 27 38 ## [8,] 11 6 3 2 3 6 11 18 27 38 51 ## [9,] 6 3 2 3 6 11 18 27 38 51 66 ## [10,] 3 2 3 6 11 18 27 38 51 66 83 ## [11,] 2 3 6 11 18 27 38 51 66 83 102 In the grid of values, what is the smallest sum of squared residuals? outer(1:3,1:3,&#39;*&#39;) ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 2 4 6 ## [3,] 3 6 9 ans &lt;- outer(-2:8,-2:8,Vectorize(fitTheRest)) unique(ans[which(ans == min(ans))]) ## [1] 2 "],
["inference-for-high-dimensional-data.html", "Chapter 6 Inference for High Dimensional Data 6.2 Exercises 6.4 Exercises 6.10 Exercises 6.12 Exercises", " Chapter 6 Inference for High Dimensional Data Note: I have rephrased some parts of the questions for clarity. These changes are bolded. Due to the random numbers, the exact values of the answers, despite the same seeds, might differ. So please be mindful of that. First, upload necessary package(s). library(dplyr) # uplaods the function filter() and %&gt;% library(rafalib) # important for plotting with base R library(genefilter) # rowttests ## ## Attaching package: &#39;genefilter&#39; ## The following object is masked from &#39;package:MASS&#39;: ## ## area #library(devtools) # allows download from github library(qvalue) # conversion from p values to q values library(GSE5859Subset) # subset of gene expression data 6.2 Exercises library(GSE5859Subset) data(GSE5859Subset) This package loads three tables: geneAnnotation, geneExpression, and sampleInfo. Answer the following questions to familiarize yourself with the data set: Question 1 How many samples were processed on 2005-06-27? length(which(sampleInfo$date == &#39;2005-06-27&#39;)) ## [1] 5 Questions 2 How many of the genes represented in this particular technology are on chromosome Y? length(which(geneAnnotation$CHR == &#39;chrY&#39;)) ## [1] 21 Question 3 What is the value of the gene ARPC1A on the one subject that we measured on 2005-06-10? subj &lt;- sampleInfo[which(sampleInfo$date == &#39;2005-06-10&#39;),]$filename probe &lt;- geneAnnotation[which(geneAnnotation$SYMBOL == &#39;ARPC1A&#39;),]$PROBEID geneExpression[probe,subj] ## [1] 8.233599 6.4 Exercises set.seed(1) population = read.csv(&#39;femaleControlsPopulation.csv&#39;) pvals &lt;- replicate(1000,{ control = sample(population[,1],12) treatment = sample(population[,1],12) t.test(treatment,control)$p.val }) head(pvals) ## [1] 0.9758457 0.4723582 0.2068672 0.7023475 0.9407852 0.0723841 hist(pvals) Question 1 What proportion of the p-values is below 0.05? mean(pvals&lt;0.05) ## [1] 0.041 Question 2 What proportion of the p-values is below 0.01? mean(pvals&lt;0.01) ## [1] 0.008 Question 3 Assume you are testing the effectiveness of 20 diets on mice weight. For each of the 20 diets, you run an experiment with 10 control mice and 10 treated mice. Assume the null hypothesis, that the diet has no effect, is true for all 20 diets and that mice weights follow a normal distribution, with mean 30 grams and a standard deviation of 2 grams. Run a Monte Carlo simulation for one of these studies: cases = rnorm(10,30,2) controls = rnorm(10,30,2) t.test(cases,controls) ## ## Welch Two Sample t-test ## ## data: cases and controls ## t = 0.16473, df = 17.934, p-value = 0.871 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -1.708669 1.999327 ## sample estimates: ## mean of x mean of y ## 30.23172 30.08639 Now run a Monte Carlo simulation imitating the results for the experiment for all 20 diets. If you set the seed at 100, set.seed(100), how many of p-values are below 0.05? set.seed(100) randomData &lt;- matrix(rnorm(20*20,30,2),20,20) g &lt;- c(rep(0,10),rep(1,10)) pvals &lt;- rowttests(randomData, factor(g))$p.value sum(pvals&lt;0.05) ## [1] 1 Question 4 Now create a simulation to learn about the distribution of the number of p-values that are less than 0.05. In question 3, we ran the 20 diet experiment once. Now we will run the experiment 1,000 times and each time save the number of p-values that are less than 0.05. Set the seed at 100, set.seed(100), run the code from Question 3 1,000 times, and save the number of times the p-value is less than 0.05 for each of the 1,000 instances. What is the average of these numbers? This is the expected number of tests (out of the 20 we run) that we will reject when the null is true. set.seed(100) res &lt;- replicate(1000, { randomData &lt;- matrix(rnorm(20*20,30,2),20,20) pvals &lt;- rowttests(randomData, factor(g))$p.value return(sum(pvals&lt;0.05)) # total number of false positives per replication }) mean(res) ## [1] 0.999 Question 5 What this says is that on average, we expect some p-value to be 0.05 even when the null is true for all diets. Use the same simulation data and report for what percent of the 1,000 replications did we make more than 0 false positives? mean(res&gt;0) ## [1] 0.651 6.10 Exercises Question 1 Assume the null is true and denote the p-value you would get if you ran a test as P. Define the function \\(f(x) = Pr(P&gt;x)\\). What does \\(f(x)\\) look like? The answer is B (identity line). When the null hypothesis is true, p value has a uniform distribution. If you plot a cumulative distribution function, where the y-axis is f(x), then you will observe an identity line. Here is a demonstration using ecdf function to plot a cumulative distribution function. population &lt;- read.csv(&#39;femaleControlsPopulation.csv&#39;) %&gt;% unlist() set.seed(1) N &lt;- 12 B &lt;- 10000 pvals &lt;- replicate(B,{ control = sample(population,N) treatment = sample(population,N) t.test(treatment,control)$p.val }) mypar(1,2) hist(pvals) plot(ecdf(pvals)) # identity line Question 2 In the previous exercises, we saw how the probability of incorrectly rejecting the null for at least one of 20 experiments for which the null is true, is well over 5%. Now let’s consider a case in which we run thousands of tests, as we would do in a high-throughput experiment. We previously learned that under the null, the probability of a p-value \\(&lt; p\\) is p. If we run 8,793 independent tests, what it the probability of incorrectly rejecting at least one of the null hypotheses? 1 - 0.95^8793 ## [1] 1 Question 3 Suppose we need to run 8,793 statistical tests and we want to make the probability of a mistake very small, say 5%. Use the answer to exercise 2 (Sidak’s procedure) to determine how small we have to change the cutoff, previously 0.05, to lower our probability of at least one mistake to be 5%. m &lt;- 8793 1 - 0.95^(1/m) ## [1] 5.833407e-06 Question 4 In R define alphas &lt;- seq(0,0.25,0.01) Make a plot of \\(\\alpha/m\\) and \\(1-(1-\\alpha)^{1/m}\\) for various values of \\(m&gt;1\\). Which procedure is more conservative Bonferrino’s or Sidek’s? plot(alphas/m, (1-(1-alphas)^(1/m)), xlab = &#39;bonf&#39;, ylab = &#39;sidak&#39;, main = &#39;p-val cutoff&#39;) abline(0,1) Bonferroni’s procedure is more conservative (choice B). Conservative refers to strictness. The p-value cutoff for significance is lower in Bonferroni’s procedure, and therefore more conservative. Question 5 To simulate the p-value results of, say 8,793 t-tests for which the null is true, we don’t actually have to generate the original data. We can generate p-values for a uniform distribution like this: pvals &lt;- runif(8793,0,1). Using what we have learned, set the cutoff using the Bonferroni correction and report back the FWER. Set the seed at 1 and run 10,000 simulations. set.seed(1) bonf_res &lt;- replicate(10000, { pvals &lt;- runif(8793,0,1) bonfcall &lt;- sum((pvals * m) &lt; 0.05) return(bonfcall) }) sum(bonf_res&gt;0)/length(bonf_res) ## [1] 0.0464 Question 6 Using the same seed, repeat exercise 5, but for Sidek’s cutoff. set.seed(1) sidak_res &lt;- replicate(10000, { pvals &lt;- runif(8793,0,1) sidakcall &lt;- sum((1-(1-pvals)^m) &lt; 0.05) return(sidakcall) }) sum(sidak_res&gt;0)/length(sidak_res) ## [1] 0.0473 Question 7 In the following exercises, we will define error controlling procedures for experimental data. We will make a list of genes based on q-values. We will also assess your understanding of false positives rates and false negative rates by asking you to create a Monte Carlo simulation. Load the expression data: library(GSE5859Subset) data(GSE5859Subset) We are interested in comparing gene expression between the two groups defined in the sampleInfo table. Compute a p-value for each gene using the function rowttests from the genefilter package. library(genefilter) #?rowttests How many genes have p-values smaller than 0.05? g &lt;- sampleInfo$group pvals &lt;- rowttests(geneExpression, factor(g))$p.value sum(pvals &lt; 0.05) ## [1] 1383 Question 8 Apply the Bonferroni correction to achieve a FWER of 0.05. How many genes are called significant under this procedure? m &lt;- 8793 sum(pvals &lt; (0.05/m)) ## [1] 10 Question 9 In R, we can compute q-values using the p.adjust function with the FDR option. Read the help file for p.adjust and compute how many genes achieve a q-value &lt; 0.05 for our gene expression dataset. pvals_adjust &lt;- p.adjust(pvals, method = &#39;fdr&#39;) sum(pvals_adjust &lt; 0.05) ## [1] 13 Question 10 Now use the qvalue function, in the Bioconductor qvalue package, to estimate q-values using the procedure described by Storey. How many genes have q-values below 0.05? res &lt;- qvalue(pvals) sum(res$qvalues &lt; 0.05) ## [1] 22 Question 11 Read the help file for qvalue and report the estimated proportion of genes for which the null hypothesis is true \\(\\pi_0 = m_0/m\\) res$pi0 ## [1] 0.6695739 Question 12 The number of genes passing the q-value &lt; 0.05 threshold is larger with the q-value function than the p.adjust difference. Why is this the case? Make a plot of the ratio of these two estimates to help answer the question. plot(pvals_adjust, res$qvalues, xlab = &#39;fdr&#39;, ylab = &#39;qval&#39;) abline(0,1) The qvalue function estimates the proportion of genes for which the null hypothesis is true and provides a less conservative estimate (choice C). Questions 13 &amp; 14 This exercise and the remaining one are more advanced. Create a Monte Carlo simulation in which you simulate measurements from 8,793 genes for 24 samples, 12 cases and 12 controls. For 500 genes, create a difierence of 1 between cases and controls. You can use the code provided below. Run this experiment 1,000 times with a Monte Carlo simulation. For each instance, compute p-values using a t-test and keep track of the number of false positives and false negatives. Compute the false positive rate and false negative rate if we use Bonferroni, q-values from p.adjust, and q-values from qvalue function. Set the seed to 1 for all three simulations. What are the false positive and false negative rates for Bonferroni? Note: False positive rate = number of false positives / total number of genes for which the null hypothesis is true. False negative rate = number of false negatives / total number of genes for which the null hypothesis is false. n &lt;- 24 m &lt;- 8793 mat &lt;- matrix(rnorm(n*m),m,n) delta &lt;- 1 positives &lt;- 500 mat[1:positives,1:(n/2)] &lt;- mat[1:positives,1:(n/2)]+delta g &lt;- c(rep(0,12),rep(1,12)) m &lt;- 8793 B &lt;- 1000 m1 &lt;- 500 N &lt;- 12 m0 &lt;- m-m1 nullHypothesis &lt;- c(rep(TRUE,m0),rep(FALSE,m1)) delta &lt;- 1 set.seed(1) res &lt;- replicate(B, { controls &lt;- matrix(rnorm(N*m),nrow = m, ncol = N) treatment &lt;- matrix(rnorm(N*m),nrow = m, ncol = N) treatment[!nullHypothesis,] &lt;- treatment[!nullHypothesis,] + delta dat &lt;- cbind(controls, treatment) pvals &lt;- rowttests(dat, factor(g))$p.value calls &lt;- pvals &lt; (0.05/m) R &lt;- sum(calls) V &lt;- sum(nullHypothesis &amp; calls) fp &lt;- sum(nullHypothesis &amp; calls)/m0 # false positive fn &lt;- sum(!nullHypothesis &amp; !calls)/m1 # false negative return(c(fp,fn)) }) res&lt;-t(res) head(res) ## [,1] [,2] ## [1,] 0.0000000000 0.998 ## [2,] 0.0000000000 0.998 ## [3,] 0.0000000000 0.992 ## [4,] 0.0001205836 0.996 ## [5,] 0.0000000000 0.992 ## [6,] 0.0000000000 0.994 mean(res[,1]) # false positive rate ## [1] 5.185096e-06 mean(res[,2]) # false negative rate ## [1] 0.995206 Questions 15 &amp; 16 What are the false positive and negative rates for p.adjust? g &lt;- c(rep(0,12),rep(1,12)) m &lt;- 8793 B &lt;- 1000 m1 &lt;- 500 N &lt;- 12 m0 &lt;- m-m1 nullHypothesis &lt;- c(rep(TRUE,m0),rep(FALSE,m1)) delta &lt;- 1 set.seed(1) res &lt;- replicate(B, { controls &lt;- matrix(rnorm(N*m),nrow = m, ncol = N) treatment &lt;- matrix(rnorm(N*m),nrow = m, ncol = N) treatment[!nullHypothesis,] &lt;- treatment[!nullHypothesis,] + delta dat &lt;- cbind(controls, treatment) pvals &lt;- rowttests(dat, factor(g))$p.value pvals_adjust &lt;- p.adjust(pvals, method = &#39;fdr&#39;) calls &lt;- pvals_adjust &lt; 0.05 R &lt;- sum(calls) V &lt;- sum(nullHypothesis &amp; calls) fp &lt;- sum(nullHypothesis &amp; calls)/m0 # false positive fn &lt;- sum(!nullHypothesis &amp; !calls)/m1 # false negative return(c(fp,fn)) }) res&lt;-t(res) head(res) ## [,1] [,2] ## [1,] 0.0000000000 0.992 ## [2,] 0.0002411672 0.966 ## [3,] 0.0000000000 0.968 ## [4,] 0.0002411672 0.950 ## [5,] 0.0000000000 0.964 ## [6,] 0.0000000000 0.944 mean(res[,1]) # false positive rate ## [1] 0.0001201013 mean(res[,2]) # false negative rate ## [1] 0.962686 Questions 17 &amp; 18 What are the false positive and negative rates for qvalues? g &lt;- c(rep(0,12),rep(1,12)) m &lt;- 8793 B &lt;- 1000 m1 &lt;- 500 N &lt;- 12 m0 &lt;- m-m1 nullHypothesis &lt;- c(rep(TRUE,m0),rep(FALSE,m1)) delta &lt;- 1 set.seed(1) res &lt;- replicate(B, { controls &lt;- matrix(rnorm(N*m),nrow = m, ncol = N) treatment &lt;- matrix(rnorm(N*m),nrow = m, ncol = N) treatment[!nullHypothesis,] &lt;- treatment[!nullHypothesis,] + delta dat &lt;- cbind(controls, treatment) pvals &lt;- rowttests(dat, factor(g))$p.value qvals &lt;- qvalue(pvals)$qvalue calls &lt;- qvals &lt; 0.05 R &lt;- sum(calls) V &lt;- sum(nullHypothesis &amp; calls) fp &lt;- sum(nullHypothesis &amp; calls)/m0 # false positive fn &lt;- sum(!nullHypothesis &amp; !calls)/m1 # false negative return(c(fp,fn)) }) res&lt;-t(res) head(res) ## [,1] [,2] ## [1,] 0.0000000000 0.988 ## [2,] 0.0002411672 0.966 ## [3,] 0.0000000000 0.950 ## [4,] 0.0002411672 0.950 ## [5,] 0.0000000000 0.964 ## [6,] 0.0000000000 0.942 mean(res[,1]) # false positive rate ## [1] 0.0001387918 mean(res[,2]) # false negative rate ## [1] 0.95894 6.12 Exercises library(rafalib) library(SpikeInSubset) ## Loading required package: Biobase ## Loading required package: BiocGenerics ## Loading required package: parallel ## ## Attaching package: &#39;BiocGenerics&#39; ## The following objects are masked from &#39;package:parallel&#39;: ## ## clusterApply, clusterApplyLB, clusterCall, ## clusterEvalQ, clusterExport, clusterMap, parApply, ## parCapply, parLapply, parLapplyLB, parRapply, ## parSapply, parSapplyLB ## The following objects are masked from &#39;package:Matrix&#39;: ## ## colMeans, colSums, rowMeans, rowSums, which ## The following objects are masked from &#39;package:dplyr&#39;: ## ## combine, intersect, setdiff, union ## The following objects are masked from &#39;package:stats&#39;: ## ## IQR, mad, sd, var, xtabs ## The following objects are masked from &#39;package:base&#39;: ## ## anyDuplicated, append, as.data.frame, basename, ## cbind, colMeans, colnames, colSums, dirname, do.call, ## duplicated, eval, evalq, Filter, Find, get, grep, ## grepl, intersect, is.unsorted, lapply, lengths, Map, ## mapply, match, mget, order, paste, pmax, pmax.int, ## pmin, pmin.int, Position, rank, rbind, Reduce, ## rowMeans, rownames, rowSums, sapply, setdiff, sort, ## table, tapply, union, unique, unsplit, which, ## which.max, which.min ## Welcome to Bioconductor ## ## Vignettes contain introductory material; view with ## &#39;browseVignettes()&#39;. To cite Bioconductor, see ## &#39;citation(&quot;Biobase&quot;)&#39;, and for packages ## &#39;citation(&quot;pkgname&quot;)&#39;. ## ## Attaching package: &#39;Biobase&#39; ## The following object is masked from &#39;package:Hmisc&#39;: ## ## contents ## Loading required package: affy data(mas133) Now make the following plot of the first two samples and compute the correlation: e &lt;- exprs(mas133) plot(e[,1],e[,2],main=paste0(&quot;corr=&quot;,signif(cor(e[,1],e[,2]),3)), cex=0.5) k &lt;- 3000 b &lt;- 1000 #a buffer polygon(c(-b,k,k,-b),c(-b,-b,k,k),col=&quot;red&quot;,density=0,border=&quot;red&quot;) Question 1 What proportion of the points are inside the box? length(which(e[,1] &lt;= 3000 &amp; e[,2]&lt;= 3000)) / dim(e)[1] ## [1] 0.9475336 sum(e[,1] &lt;= 3000 &amp; e[,2] &lt;= 3000) / dim(e)[1] ## [1] 0.9475336 Question 2 Now make the sample plot with log: plot(log2(e[,1]),log2(e[,2])) k &lt;- log2(3000) b &lt;- log2(0.5) polygon(c(b,k,k,b),c(b,b,k,k),col=&quot;red&quot;,density=0,border=&quot;red&quot;) What is an advantage of taking the log? The answer choice is A: The tails do not dominate the plot, 95% of data are not in a tiny section of the plot. Question 3 Make an MA-plot: e &lt;- log2(exprs(mas133)) plot((e[,1]+e[,2])/2,e[,2]-e[,1],cex=0.5) The two samples we are plotting are replicates (they are random samples from the same batch of RNA). The correlation of the data was 0.997 in the original scale and 0.96 in the log-scale. High correlations are sometimes confused with evidence of replication. However, replication implies we get very small differences between the observations, which is better measured with distance or differences. What is the standard deviation of the log ratios for this comparison? e &lt;- log2(exprs(mas133)) plot((e[,1]+e[,2])/2,e[,2]-e[,1],cex=0.5) sd(e[,2]-e[,1]) ## [1] 0.7767887 Question 4 How many fold changes above absolute 2 do we see? sum(abs(e[,2]-e[,1])&gt;1) ## [1] 3057 "],
["statistical-models.html", "Chapter 7 Statistical Models 7.5 Exercises 7.9 Exericses", " Chapter 7 Statistical Models Note: I have rephrased some parts of the questions for clarity. These changes are bolded. Due to the random numbers, the exact values of the answers, despite the same seeds, might differ. So please be mindful of that. First, upload necessary package(s). library(dplyr) # uplaods the functions filter() and %&gt;% library(rafalib) # important for plotting with base R 7.5 Exercises Question 1 The probability of conceiving a girl is 0.49. What is the probability that a family with 4 children has 2 girls and 2 boys (you can assume that the outcomes are independent)? p &lt;- 0.49 dbinom(2,4,p=p) ## [1] 0.3747001 dbinom and pbinom are different. pbinom is cumulative, whereas dibnom is for individual value. Here is a demonstration. They are all equal. p &lt;- 0.49 dbinom(2,4,p=p) ## [1] 0.3747001 pbinom(2,4,p=p) ## [1] 0.702348 dbinom(0,4,p=p) + dbinom(1,4,p=p) + dbinom(2,4,p=p) ## [1] 0.702348 Question 2 What is the probability that a family with 10 children has 6 girls and 4 boys (assume no twins)? p &lt;- 0.49 dbinom(6,10,p=p) ## [1] 0.1966421 Question 3 The genome has 3 billion bases. About 20% are C, 20% are G, 30% are T, and 30% are A. Suppose you take a random interval of 20 bases, what is the probability that the GC-content (proportion of Gs of Cs) is strictly above 0.5 in this interval? p &lt;- 0.4 pbinom(20,20,p) - pbinom(10,20,p) ## [1] 0.1275212 Question 4 The probability of winning the lottery is 1 in 175,223,510. If 20,000,000 people buy a ticket, what is the probability that more than one person wins? p &lt;- 1/175233510 N &lt;- 20000000 1 - ppois(1,N*p) ## [1] 0.006038215 1 - pbinom(1,N,p) ## [1] 0.006038215 Since the poisson distrubtion is a type of binomial distribution, both distribution give the same values. Question 5 The genome has 3 billion bases. About 20% are C, 20% are G, 30% are T, and 30% are A. Suppose you take a random interval of 20 bases, what is the exact probability that the GC-content (proportion of Gs of Cs) is greater than 0.35 and smaller or equal to 0.45 in this interval? p &lt;- 0.4 pbinom(0.45*20, 20, p) - pbinom(0.35*20,20,p) ## [1] 0.3394443 Question 6 For the question above, what is the normal approximation to the probability? p &lt;- 0.4 N &lt;- 20 a &lt;- (0.45*20 - N*p) / sqrt(N*p*(1-p)) b &lt;- (0.35*20 - N*p) / sqrt(N*p*(1-p)) approx &lt;- pnorm(a) - pnorm(b) approx ## [1] 0.3519231 Question 7 Repeat Question 5, but using an interval of 1000 bases. What is the difference (in absolute value) between the normal approximation and the exact distribution of the GC-content being greater than 0.35 and lesser or equal to 0.45? N &lt;- 1000 p &lt;- 0.4 a &lt;- (0.45*N - N*p) / sqrt(N*p*(1-p)) b &lt;- (0.35*N - N*p) / sqrt(N*p*(1-p)) approx &lt;- pnorm(a) - pnorm(b) exact &lt;- pbinom(0.45*N,N,p) - pbinom(0.35*N,N,p) exact - approx ## [1] 9.728752e-06 Question 8 The Cs in our genomes can be methylated or unmethylated. Suppose we have a large (millions) group of cells in which a proportion p of the Cs of interest are methylated. We break up the DNA of these cells and randomly select pieces and end up with \\(N\\) pieces that contain the C we care about. This means that the probability of seeing \\(k\\) methylated Cs is binomial: exact = dbinom(k,N,p) ## Warning in dbinom(k, N, p): non-integer x = 11.550747 We can approximate this with the normal distribution: a &lt;- (k+0.5 - N*p)/sqrt(N*p*(1-p)) b &lt;- (k-0.5 - N*p)/sqrt(N*p*(1-p)) approx = pnorm(a) - pnorm(b) Compute the difference approx-exact for: N &lt;- c(5,10,50,100,500) p &lt;- seq(0,1,0.25) Compare the approximation and exact probability of the proportion of Cs being \\(p\\), \\(k = 1,...,N-1\\) plotting the exact versus the approximation for each \\(p\\) and \\(N\\) combination. Which statement is false? Ns &lt;- c(5,10,50,100,500) Ps &lt;- seq(0,1,0.25) mypar(5,5) for (i in seq_along(Ns)) { n &lt;- Ns[[i]] k &lt;- seq(1:n-1) for (j in seq_along(Ps)) { p &lt;- Ps[[j]] exact = dbinom(k, n, p) a = (k+0.5- n*p)/sqrt(n*p*(1-p)) b = (k-0.5- n*p)/sqrt(n*p*(1-p)) approx = pnorm(a) - pnorm(b) qqplot(exact,approx,xlab=&#39;exact&#39;,ylab=&#39;approx&#39;, main = paste0(&#39;N=&#39;,n,&#39; &#39;,&#39;p=&#39;,p)) abline(0,1) } } The answer is C: When N is 100 all approximations are spot on. When p is close to 0 or 1, the normal distribution breaks down even at N = 100. Question 9 We saw in the previous question that when p is very small, the normal approximation breaks down. If N is very large, then we can use the Poisson approximation. Earlier we computed 1 or more people winning the lottery when the probability of winning was 1 in 175,223,510 and 20,000,000 people bought a ticket. Using the binomial, we can compute the probability of exactly two people winning to be: N &lt;- 20000000 p &lt;- 1/175223510 dbinom(2,N,p) ## [1] 0.005811321 If we were to use the normal approximation, we would greatly underestimate this: a &lt;- (2+0.5 - N*p)/sqrt(N*p*(1-p)) b &lt;- (2-0.5 - N*p)/sqrt(N*p*(1-p)) pnorm(a) - pnorm(b) ## [1] 2.04756e-05 To use the Poisson approximation here, use the rate \\(\\lambda = Np\\) representing the number of people per 20,000,000 that win the lottery. Note how much better the approximation is: dpois(2,N*p) ## [1] 0.005811321 In this case, it is practically the same because N is very large and Np is not 0. These are the assumptions needed for the Poisson to work. What is the Poisson approximation for more than one person winning? 1 - ppois(1,N*p) ## [1] 0.006038879 Question 10 Write a function that takes \\(\\lambda\\) and the vector of counts as input and returns the log-likelihood. Compute this log-likelihood for lambdas = seq(0,15,len=300) and make a plot. What value of lambdas maximizes the log-likelihood? library(dagdata) data(hcmv) mypar() plot(locations,rep(1,length(locations)),ylab=&quot;&quot;,yaxt=&quot;n&quot;) breaks=seq(0,4000*round(max(locations)/4000),4000) tmp=cut(locations,breaks) counts=as.numeric(table(tmp)) hist(counts) probs &lt;- dpois(counts,4) likelihood &lt;- prod(probs) likelihood ## [1] 1.177527e-62 logprobs &lt;- dpois(counts,4,log=T) loglikelihood &lt;- sum(logprobs) loglikelihood ## [1] -142.5969 loglike = function(lambdas) { logprobs &lt;- dpois(counts,lambdas,log=T) loglikelihood &lt;- sum(logprobs) return(loglikelihood) } lambdas &lt;- seq(0,15,len=300) log_res &lt;- exp(sapply(lambdas,loglike)) optim_lambda &lt;- lambdas[which(log_res == max(log_res))] Question 11 The point of collecting this dataset was to try to determine if there is a region of the genome that has a higher palindrome rate than expected. We can create a plot and see the counts per location: library(dagdata) data(hcmv) breaks=seq(0,4000*round(max(locations)/4000),4000) tmp=cut(locations,breaks) counts=as.numeric(table(tmp)) binLocation=(breaks[-1]+breaks[-length(breaks)])/2 plot(binLocation,counts,type=&quot;l&quot;,xlab=) What is the center of the bin with the highest count? binLocation[which(counts == max(counts))] ## [1] 94000 Question 12 What is the maximum count? max(counts) ## [1] 14 Question 13 Once we have identified the location with the largest palindrome count, we want to know if we could see a value this big by chance. If X is a Poisson random variable with rate: lambda = mean(counts[-which.max(counts)]) What is the probability of seeing a count of 14 or more? 1 - ppois(13, lambda) ## [1] 0.00069799 You subtract ppois(13,optim_lambda) because you need to exclude it. Since this distribution is discrete, 1 - ppois(13, optim_lambda) will count probability from a seeing a count of 14 or more. Question 14 So we obtain a p-value smaller than 0.001 for a count of 14. Why is it problematic to report this p-value as strong evidence of a location that is different? The answer is B: We selected the highest region out of 57 and need to adjust for multiple testing. Answer A is wrong because we do use normal approximation in t-test to get a p-value, so there is nothing wrong with using approximation. Answer B is correct because the p-value that we obtained is from a comparison against the sample mean (z score = 0) rather than all other counts. Therefore, the p-value must be corrected (ex. Bonferroni’s procedure). Answer C is wrong because p value can also be a random variable, but this answer choice implies that p-value is not a random variable. Answer D is wrong because effect size is irrelevent. Question 15 Use the Bonferroni correction to determine the p-value cut-off that guarantees a FWER of 0.05. What is this p-value cutoff? 0.05/length(counts) ## [1] 0.000877193 Question 16 Create a qq-plot to see if our Poisson model is a good fit: ps &lt;- (seq(along=counts) - 0.5)/length(counts) lambda &lt;- mean( counts[ -which.max(counts)]) poisq &lt;- qpois(ps,lambda) plot(poisq,sort(counts)) abline(0,1) How would you characterize this qq-plot - A) Poisson is a terrible approximation. - B) Poisson is a very good approximation except for one point that we actually think is a region of interest. - C) There are too many 1s in the data. - D) A normal distribution provides a better approximation. The answer is B. You can check whether the palindrome counts are well approximated by the normal distribution. qqnorm(sort(counts)) Question 17 Load the tissuesGeneExpression data library: library(tissuesGeneExpression) data(&quot;tissuesGeneExpression&quot;) Then select the columns related to endometrium: library(genefilter) y = e[,which(tissue==&quot;endometrium&quot;)] This will give you a matrix y with 15 samples. Compute the across sample variance for the first three samples. Then make a qq-plot to see if the data follow a normal distribution. Which of the following is true? - A) With the exception of a handful of outliers, the data follow a normal distribution. - B) The variance does not follow a normal distribution, but taking the square root fixes this. - C) The normal distribution is not usable here: the left tail is over estimated and the right tail is underestimated. - D) The normal distribution fits the data almost perfectly. vars &lt;- rowVars(y[,1:3]) length(vars) ## [1] 22215 mypar(1,2) qqnorm(sqrt(vars)) # choice B is false qqnorm(vars) # choice A and D are false The answer is C. Question 18 Now fit an F-distribution with 14 degrees of freedom using the fitFDist function in the limma package. What are df2 and scale ? library(limma) ## ## Attaching package: &#39;limma&#39; ## The following object is masked from &#39;package:BiocGenerics&#39;: ## ## plotMA res &lt;- fitFDist(vars,14) res ## $scale ## [1] 0.01139807 ## ## $df2 ## [1] 1.217793 Question 19 Now create a qq-plot of the observed sample variances versus the F-distribution quantiles. Which of the following best describes the qq-plot? pf &lt;- (seq(along=vars)-0.5)/length(vars) theory &lt;- qf(pf,14,res$df2) # theoretical quantiles from F distribution mypar(1,2) qqplot(theory, sort(vars), xlab = &#39;theory&#39;, ylab =&#39;obs&#39;) # F approximation vs variance from the data qqnorm(sort(vars)) # normal approximation vs variance from the data The answer is D: If we exclude the highest 0.1% of the data, the F-distribution provides a good fit. Actually I do not think answer is entirely correct but this is the most appropriate one. Even if we exclude the top 0.1% there are still more outliers to remove. Here is a demonstration. vars_sort &lt;- sort(vars) vars_excl &lt;- vars_sort[1:18000] # 18000 out of 22215 kept = 81% pf_excl &lt;- (seq(along=vars_excl)-0.5)/length(vars_excl) theory &lt;- qf(pf_excl,14,res$df2) mypar(2,2) qqplot(theory,vars_excl, xlab = &#39;theory&#39;,ylab=&#39;obs&#39;, main = &#39;all data compared with F-approximation&#39;) qqplot(vars_excl,theory, xlim = c(0,0.2), ylim = c(0,100), main = &#39;zoomed in&#39;) qqnorm(vars_excl, main = &#39;normal qqplot&#39;) # comparing with normal approximation with filtered variance (81% kept) Even if I keep up to 81% of the values, F-distribution ## 7.7 Exercises {-} Question 1 A test for cystic fibrosis has an accuracy of 99%. Specifically, we mean that: \\[ \\begin{align*} Prob(+|D) = 0.99, Prob(-|no D) = 0.99 \\end{align*} \\] The cystic fibrosis rate in the general population is 1 in 3,900, Prob(D) = 0:00025. If we select a random person and they test positive, what is probability that they have cystic fibrosis \\(Prob(D|+)\\) ? Hint: use Bayes Rule. (0.99*0.00025)/(0.99*0.00025 + 0.01*(1-0.00025)) ## [1] 0.02415813 Question 2 First download some baseball statistics. tmpfile &lt;- tempfile() tmpdir &lt;- tempdir() download.file(&quot;http://seanlahman.com/files/database/lahman-csv_2014-02-14.zip&quot;,tmpfile) ##this shows us files filenames &lt;- unzip(tmpfile,list=TRUE) players &lt;- read.csv(unzip(tmpfile,files=&quot;Batting.csv&quot;,exdir=tmpdir),as.is=TRUE) unlink(tmpdir) file.remove(tmpfile) ## [1] TRUE We will use the dplyr, which you can read about here to obtain data from 2010, 2011, and 2012, with more than 500 at bats (AB &gt;= 500). dat &lt;- filter(players,yearID&gt;=2010, yearID &lt;=2012) %&gt;% mutate(AVG=H/AB) %&gt;% filter(AB&gt;500) What is the average of these batting averages? mean(dat$AVG,na.rm=T) ## [1] 0.2753465 Question 3 What is the standard deviation of these batting averages? sd(dat$AVG,na.rm=T) ## [1] 0.02741713 Question 4 Use exploratory data analysis to decide which of the following distributions approximates our AVG: mypar(1,2) hist(dat$AVG) qqnorm(dat$AVG) The answer is A: Normal. Question 5 It is April and after 20 at bats, Jos Iglesias is batting .450 (which is very good). We can think of this as a binomial distribution with 20 trials, with probability of success p. Our sample estimate of p is .450. What is our estimate of standard deviation? Hint: This is the sum that is binomial divided by 20. p &lt;- 0.45 n &lt;- 20 sqrt(p*(1-p)/n) ## [1] 0.111243 Question 6 The Binomial is approximated by normal, so our sampling distribution is approximately normal with mean \\(Y\\) = 0.45 and SD \\(\\sigma\\) = 0.11. Earlier we used a baseball database to determine that our prior distribution is Normal with mean \\(\\mu\\) = 0.275 and SD \\(\\tau\\) = 0.027. We also saw that this is the posterior mean prediction of the batting average. What is your Bayes prediction for the batting average going forward? B &lt;- (0.11^2)/(0.11^2 + 0.027^2) post_u &lt;- 0.275*B + (1-B)*0.45 post_u ## [1] 0.2849443 7.9 Exericses library(Biobase) library(SpikeInSubset) data(rma95) y &lt;- exprs(rma95) pData(rma95) ## 37777_at 684_at 1597_at 38734_at 39058_at ## 1521a99hpp_av06 0.00 0.25 0.5 1 2 ## 1532a99hpp_av04 0.00 0.25 0.5 1 2 ## 2353a99hpp_av08 0.00 0.25 0.5 1 2 ## 1521b99hpp_av06 0.25 0.50 1.0 2 4 ## 1532b99hpp_av04 0.25 0.50 1.0 2 4 ## 2353b99hpp_av08r 0.25 0.50 1.0 2 4 ## 36311_at 36889_at 1024_at 36202_at 36085_at ## 1521a99hpp_av06 4 8 16 32 64 ## 1532a99hpp_av04 4 8 16 32 64 ## 2353a99hpp_av08 4 8 16 32 64 ## 1521b99hpp_av06 8 16 32 64 128 ## 1532b99hpp_av04 8 16 32 64 128 ## 2353b99hpp_av08r 8 16 32 64 128 ## 40322_at 407_at 1091_at 1708_at 33818_at 546_at ## 1521a99hpp_av06 128 0.00 512 1024 256 32 ## 1532a99hpp_av04 128 0.00 512 1024 256 32 ## 2353a99hpp_av08 128 0.00 512 1024 256 32 ## 1521b99hpp_av06 256 0.25 1024 0 512 64 ## 1532b99hpp_av04 256 0.25 1024 0 512 64 ## 2353b99hpp_av08r 256 0.25 1024 0 512 64 g &lt;- factor(rep(0:1,each=3)) spike &lt;- rownames(y) %in% colnames(pData(rma95)) Question 1 Only these 16 genes are diferentially expressed since the six samples differ only due to sampling (they all come from the same background pool of RNA). Perform a t-test on each gene using the rowttest function. What proportion of genes with a p-value &lt; 0.01 (no multiple comparison correction) are not part of the artifcially added (false positive)? pval &lt;- rowttests(y,g)$p.value head(pval &lt; 0.01) ## [1] FALSE FALSE FALSE FALSE FALSE FALSE nrow(y[spike,]) ## [1] 16 sum(pval[spike] &lt; 0.01) # 11 ## [1] 11 (nrow(y[pval &lt; 0.01,]) - sum(pval[spike] &lt; 0.01))/ nrow(y[pval &lt; 0.01,]) ## [1] 0.7608696 Question 2 Now compute the within group sample standard deviation for each gene (you can use group 1). Based on the p-value cut-off, split the genes into true positives, false positives, true negatives and false negatives. Create a boxplot comparing the sample SDs for each group. Which of the following best describes the boxplot? calls &lt;- pval &lt; 0.01 # calls for significance sds_y &lt;- rowSds(y) # std for each gene fp &lt;- sds_y[calls &amp; !spike] # false positive fn &lt;- sds_y[!calls &amp; spike] # false negative tn &lt;- sds_y[!spike] # true negative tp &lt;- sds_y[spike] # true positive res &lt;- list(tp,fp,tn,fn) names(res) &lt;- c(&#39;tp&#39;,&#39;fp&#39;,&#39;tn&#39;,&#39;fn&#39;) boxplot(res, ylim = c(0,1)) The answer is D: The false positives have smaller standard deviation. Question 3 In the previous two questions, we observed results consistent with the fact that the random variability associated with the sample standard deviation leads to t-statistics that are large by chance. The sample standard deviation we use in the t-test is an estimate and with just a pair of triplicate samples, the variability associated with the denominator in the t-test can be large. The following steps perform the basic limma analysis. We specify coef=2 because we are interested in the difference between groups, not the intercept. The eBayes step uses a hierarchical model that provides a new estimate of the gene specific standard error. library(limma) fit &lt;- lmFit(y, design=model.matrix(~ g)) colnames(coef(fit)) ## [1] &quot;(Intercept)&quot; &quot;g1&quot; fit &lt;- eBayes(fit) Here is a plot of the original, new, hierarchical models based estimate versus the sample based estimate: sampleSD = fit$sigma posteriorSD = sqrt(fit$s2.post) Which best describes what the hierarchical model does? hist(sampleSD, xlim = c(0,.5)) hist(posteriorSD, xlim = c(0,.5)) mean(sampleSD) ## [1] 0.1241865 The answer choice is A: Moves all esimates of standard deviation closer to 0.12. Question 4 Use these new estimates of standard deviation in the denominator of the t-test and compute p-values. You can do it like this: library(limma) fit = lmFit(y, design=model.matrix(~ g)) fit = eBayes(fit) ##second coefficient relates to diffences between group pvals = fit$p.value[,2] What proportion of genes with a p-value &lt; 0.01 (no multiple comparison correction) are not part of the artificially added (false positive)? pvals &lt;- fit$p.value[,2] (nrow(y[pvals &lt; 0.01,]) - sum(pvals[spike] &lt; 0.01))/ nrow(y[pvals &lt; 0.01,]) ## [1] 0.6486486 "],
["distance-and-dimension-reduction.html", "Chapter 8 Distance and Dimension Reduction 8.4 Exercises 8.7 Exercises 8.11 Exercises", " Chapter 8 Distance and Dimension Reduction Note: I have rephrased some parts of the questions for clarity. These changes are bolded. Due to the random numbers, the exact values of the answers, despite the same seeds, might differ. So please be mindful of that. First, upload necessary package(s). library(dplyr) # uplaods the function filter() and %&gt;% library(rafalib) # important for plotting with base R library(genefilter) # rowttests #library(devtools) # allows download from github library(GSE5859Subset) # subset of gene expression data library(tissuesGeneExpression) data(tissuesGeneExpression) 8.4 Exercises Question 1 How many biological replicates for hippocampus? head(tissue) # from data(tissuesGeneExpression) ## [1] &quot;kidney&quot; &quot;kidney&quot; &quot;kidney&quot; &quot;kidney&quot; &quot;kidney&quot; &quot;kidney&quot; table(tissue)[&#39;hippocampus&#39;] ## hippocampus ## 31 Question 2 What is the distance between samples 3 and 45? d &lt;- dist(t(e)) as.matrix(d)[3,45] ## [1] 152.5662 x &lt;- e[,3] y &lt;- e[,45] sqrt(crossprod(x-y)) ## [,1] ## [1,] 152.5662 Question 3 What is the distance between gene 210486 and 200805_at? x &lt;- e[which(rownames(e)==&#39;210486_at&#39;),] y &lt;- e[which(rownames(e)==&#39;200805_at&#39;),] sqrt(crossprod(x-y)) ## [,1] ## [1,] 41.01153 Question 4 If I run the command (don’t run it) d = as.matrix(dist(e)) how many cells (the number of rows times number of columns) will this matrix have? 22215 x 22215. dist computes distance between each row. So there will be 22215 x 22215 combinations of distance in the matrix form that dist can compute in data e, which has 22215 rows. In matrix form of the distance data, there are repeated combinations. If we instead put t(e) as input to run dist function, we will have 189 x 189 possible distances in the matrix form since t(e) has 189 rows. Question 5 Compute the distance between all pair of samples: d = dist(t(e)) Read help file for dist. How many distances are stored in d? Hint: What is the length of d? length(d) ## [1] 17766 Question 6 Why is the answer to Question 5 not ncol(e)^2? The answer is C: Because we take advantage of symmetry: only the lower triangular matrix of the full distance matrix is stored thus, only ncol(e)*(ncol(e)-1)/2 values. If you are still confused, you can run this demonstration. set.seed(1) random_number &lt;- matrix(rnorm(4*4),4,4) # 4x4 matrix of random numbers d_random &lt;- dist(random_number) d_random ## 1 2 3 ## 2 2.300929 ## 3 1.998475 4.147861 ## 4 2.338790 3.100611 2.932507 as.matrix(d_random) ## 1 2 3 4 ## 1 0.000000 2.300929 1.998475 2.338790 ## 2 2.300929 0.000000 4.147861 3.100611 ## 3 1.998475 4.147861 0.000000 2.932507 ## 4 2.338790 3.100611 2.932507 0.000000 Notice that all the repeated combinations of two rows in random_number are removed in d_random. Also, there is 0 distance between the same row (1st row vs 1st row), so this is removed in d_random too. However, these numbers are displayed after it is converted into matrix. 8.7 Exercises library(tissuesGeneExpression) data(tissuesGeneExpression) Question 1 Compute the SVD of e s = svd(e) Now compute the mean of each row: m = rowMeans(e) What is the correlation between the first column of U and m? U &lt;- s$u cor(U[,1],m) ## [1] -0.9999998 Question 2 In Question 1 we saw how the first column relates to the mean of the rows of e. If we change these means, the distances between the columns do not change. For example, changing the mean does not change the distance. newmeans = rnorm(nrow(e)) ##random values we will add to create new means newe = e+newmeans ##we change the means sqrt(crossprod(e[,3]-e[,45])) ## [,1] ## [1,] 152.5662 sqrt(crossprod(newe[,3]-newe[,45])) ## [,1] ## [1,] 152.5662 So we might as well make the mean of each row 0, since it does not help us approximate the column distances. We will define y as the detrended e and recompute the SVD: y = e - rowMeans(e) s = svd(y) We showed that \\(UDV^T\\) is equal to y up to numerical error: resid = y - s$u %*% diag(s$d) %*% t(s$v) max(abs(resid)) ## [1] 1.188383e-12 The above can be made more efficient in two ways. First using the crossprod and, second, not creating a diagonal matrix. In R, we can multiply matrices x by vector a. The result is a matrix with rows i equal to x[i,]*a[i]. Run the following example to see this. x=matrix(rep(c(1,2),each=5),5,2) x*c(1:5) ## [,1] [,2] ## [1,] 1 2 ## [2,] 2 4 ## [3,] 3 6 ## [4,] 4 8 ## [5,] 5 10 which is equivalent to: sweep(x,1,1:5,&quot;*&quot;) ## [,1] [,2] ## [1,] 1 2 ## [2,] 2 4 ## [3,] 3 6 ## [4,] 4 8 ## [5,] 5 10 This means that we don’t have to convert s$d into a matrix. Which of the following gives us the same as diag(s$d) %*% t(s$v)? identical(diag(s$d) %*% t(s$v),t(s$v) * s$d) ## [1] TRUE identical(s$d * t(s$v), t(s$v) * s$d) ## [1] TRUE Use identical or near function to compare each answer choice. The answer is B: s$d * t(s$v). To fully understand this question, you will need to understand how a vector and matrix multiply * together in R. s$d is a vector, and s$v is a matrix. is.vector(s$d) # it is not matrix ## [1] TRUE is.matrix(s$v) # it is not vector ## [1] TRUE Question 3 If we define vd = t(s$d * t(s$v)), then which of the following is not the same as \\(UDV^T\\)? vd = t(s$d * t(s$v)) identical(s$d * t(s$v), t(vd)) ## [1] TRUE #(t(s$d) * s$u) %*% t(s$v) yhat &lt;- s$u %*% t(vd) identical(s$u %*% (s$d * t(s$v)),yhat) ## [1] TRUE #identical(s$u %*% s$d * t(s$v),yhat) all(near(tcrossprod(t(s$d*t(s$u)),s$v),yhat)) ## [1] TRUE The answer is B: s$u %*% s$d * t(s$v). Question 4 Let z = s$d * t(s$v). We showed a derivation demonstrating that because U is orthogonal, the distance between e[,3] and e[,45] is the same as the distance between y[,3] and y[,45], which is the same as vd[,3] and vd[,45] z = s$d * t(s$v) sqrt(crossprod(e[,3]-e[,45])) # raw data ## [,1] ## [1,] 152.5662 sqrt(crossprod(y[,3]-y[,45])) # standardized data ## [,1] ## [1,] 152.5662 sqrt(crossprod(z[,3]-z[,45])) # principal compoennt ## [,1] ## [1,] 152.5662 Note that the columns of z have 189 entries, compared to 22,215 for e. What is the difference, in absolute value, between the actual distance: sqrt(crossprod(e[,3]-e[,45])) ## [,1] ## [1,] 152.5662 and the approximation using only two dimensions of z? sqrt(crossprod(e[,3]-e[,45])) - sqrt(crossprod(z[1:2,3]-z[1:2,45])) ## [,1] ## [1,] 40.62416 Recall that s$d describes proportion of variability for each principal component. However, each column of s$v represents each dimension (i.e., principal component). Since z is a product of s$d and t(s$v), the column of s$v now becomes part of the row of z. Therefore, each row of z now represents dimension. Question 5 How many dimensions do we need to use for the approximation in Question 4 to be within 10%? actual &lt;- sqrt(crossprod(e[,3]-e[,45])) percent &lt;- vector(&#39;double&#39;, nrow(z)) for (i in seq_along(percent)) { percent[[i]] &lt;- (actual - sqrt(crossprod(z[1:i,3]-z[1:i,45])))/actual } ind &lt;- min(which(percent &lt; 0.10)) ind ## [1] 7 Question 6 Compute distances between sample 3 and all other samples. actual &lt;- as.matrix(dist(t(z)))[,3] actual ## 1 2 3 4 5 6 ## 84.38089 112.12484 0.00000 95.48853 103.02366 41.39058 ## 7 8 9 10 11 12 ## 120.54709 36.66649 116.54225 39.98554 104.62072 40.10262 ## 13 14 15 16 17 18 ## 95.22417 37.43360 103.77843 46.22469 153.60546 159.44848 ## 19 20 21 22 23 24 ## 158.23033 156.64142 162.45229 154.29005 155.71326 156.25691 ## 25 26 27 28 29 30 ## 152.20062 150.52553 161.24814 168.10634 164.49951 171.58095 ## 31 32 33 34 35 36 ## 170.24450 153.52016 156.55839 161.07539 154.90893 157.61983 ## 37 38 39 40 41 42 ## 157.12698 156.93071 148.09296 156.37590 153.24192 157.81780 ## 43 44 45 46 47 48 ## 148.30794 147.54293 152.56616 153.65874 164.69072 158.77685 ## 49 50 51 52 53 54 ## 170.34769 168.79908 164.20355 166.28936 171.72410 160.05604 ## 55 56 57 58 59 60 ## 164.09831 158.68927 161.63299 164.91892 164.79351 163.56547 ## 61 62 63 64 65 66 ## 166.59989 167.62435 169.44196 172.55600 163.57509 171.89005 ## 67 68 69 70 71 72 ## 158.20437 159.96501 160.61071 171.25465 166.53772 166.44195 ## 73 74 75 76 77 78 ## 163.15348 62.30391 119.00899 115.62884 63.82724 114.17344 ## 79 80 81 82 83 84 ## 110.82250 120.55301 103.46344 51.06013 113.66075 116.50881 ## 85 86 87 88 89 90 ## 110.49660 119.25277 131.03507 133.61119 133.14274 139.96254 ## 91 92 93 94 95 96 ## 132.27121 127.30041 130.97078 136.00334 137.96283 136.13730 ## 97 98 99 100 101 102 ## 141.05467 131.06920 137.78546 132.91823 126.05454 129.27069 ## 103 104 105 106 107 108 ## 138.11669 132.97576 138.75735 136.01474 135.14692 134.83457 ## 109 110 111 112 113 114 ## 133.94075 139.59132 129.95129 131.93296 132.09485 132.79052 ## 115 116 117 118 119 120 ## 135.67441 127.34644 135.19080 129.27466 127.99943 128.82659 ## 121 122 123 124 125 126 ## 88.05529 89.69452 102.98278 133.53410 134.44093 133.04278 ## 127 128 129 130 131 132 ## 89.78634 90.87303 91.06495 132.95120 135.26307 134.99663 ## 133 134 135 136 137 138 ## 92.81078 87.71962 154.40639 155.35270 138.55124 144.02792 ## 139 140 141 142 143 144 ## 137.71813 134.93648 141.51875 140.16215 165.64068 165.52451 ## 145 146 147 148 149 150 ## 172.36133 172.60481 138.27076 119.35965 128.31795 135.37817 ## 151 152 153 154 155 156 ## 129.86141 129.53708 135.17874 129.74547 127.67693 126.07782 ## 157 158 159 160 161 162 ## 137.80298 137.65179 132.81058 143.50110 136.17646 132.49355 ## 163 164 165 166 167 168 ## 135.20594 141.87962 139.84780 142.18828 141.56300 141.87962 ## 169 170 171 172 173 174 ## 142.18828 141.56300 139.84780 139.08274 139.02476 142.96349 ## 175 176 177 178 179 180 ## 143.28705 146.46947 156.49378 163.16367 154.50386 148.70081 ## 181 182 183 184 185 186 ## 165.59121 161.49215 175.57875 178.92871 174.51879 164.19632 ## 187 188 189 ## 164.93630 164.13792 169.21046 Question 7 Recompute this distance using the two dimensional approximation. What is the Spearman correlation between this approximate distance (z) and the actual distance? approx2 &lt;- as.matrix(dist(t(z[1:2,])))[,3] cor.test(approx2,actual,method=&#39;spearman&#39;)$estimate ## Warning in cor.test.default(approx2, actual, method = ## &quot;spearman&quot;): Cannot compute exact p-value with ties ## rho ## 0.8620731 8.11 Exercises Question 1 Using the z we computed in Question 4 of the previous exercises library(tissuesGeneExpression) data(tissuesGeneExpression) y = e - rowMeans(e) s = svd(y) z = s$d * t(s$v) e can make an mds plot: library(rafalib) ftissue = factor(tissue) mypar(1,1) plot(z[1,],z[2,],col=as.numeric(ftissue)) legend(&quot;topleft&quot;,levels(ftissue),col=seq_along(ftissue),pch=1) Now run the function cmdscale on the original data: d = dist(t(e)) mds = cmdscale(d) What is the absolute value of the correlation between the first dimension of z and the first dimension in mds? cor(z[1,],mds[,1]) ## [1] -1 Question 2 What is the absolute value of the correlation between the second dimension of z and the second dimension in mds? cor(z[2,],mds[,2]) ## [1] -1 Question 3 Load the following dataset: library(GSE5859Subset) data(GSE5859Subset) Compute the svd and compute z. s = svd(geneExpression-rowMeans(geneExpression)) z = s$d * t(s$v) Which dimension of z most correlates with the outcome sampleInfo$group? s = svd(geneExpression - rowMeans(geneExpression)) z = s$d * t(s$v) sampleInfo$group ## [1] 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 res &lt;- vector(&#39;double&#39;,nrow(z)) for (i in seq_along(res)) { res[[i]] &lt;- cor(sampleInfo$group, z[i,]) } which(res == max(abs(res))) ## [1] 1 Question 4 What is this max correlation? max(res) ## [1] 0.6236858 Question 5 Which dimension of z has the second highest correlation with the outcome sampleInfo$group? ind &lt;- which(res == sort(res,decreasing = T)[2]) ind ## [1] 6 Question 6 Note these measurements were made during two months: sampleInfo$date We can extract the month this way: month = format( sampleInfo$date, &quot;%m&quot;) month = factor( month) Which dimension of z has the second highest correlation with the outcome month? month = format( sampleInfo$date, &quot;%m&quot;) month = as.numeric(month) res &lt;- vector(&#39;double&#39;,nrow(z)) for (i in seq_along(res)) { res[[i]] &lt;- cor(month, z[i,]) } ind &lt;- which(res == sort(res,decreasing = T)[2]) ind ## [1] 2 Question 7 What is this correlation? res[ind] ## [1] 0.4479168 Question 8 The same dimension is correlated with both the group and the date. The following are also correlated: table(sampleInfo$g, month) ## month ## 6 10 ## 0 9 3 ## 1 3 9 So is this first dimension related directly to group or is it related only through the month? Note that the correlation with month is higher. This is related to batch effects which we will learn about later. In Question 3 we saw that one of the dimensions was highly correlated to the sampleInfo$group. Now take the 5th column of \\(U\\) and stratify by the gene chromosome. Remove chrUn and make a boxplot of the values of \\(U_5\\) stratified by chromosome. Which chromosome looks different from the rest? Copy and paste the name as it appears in geneAnnotation. gene_list &lt;- split(geneAnnotation$PROBEID, geneAnnotation$CHR) res &lt;- split(s$u[,5], geneAnnotation$CHR) res$chrUn &lt;- NULL res &lt;- rev(res) # reverse the order of the list so that chrY is the first x-axis tick mypar() boxplot(res) chrY is the answer. "],
["basic-machine-learning.html", "Chapter 9 Basic Machine Learning 9.2 Exercises 9.4 Exercises 9.8 Exercises 9.11 Exercises", " Chapter 9 Basic Machine Learning Note: I have rephrased some parts of the questions for clarity. These changes are bolded. Due to the random numbers, the exact values of the answers, despite the same seeds, might differ. So please be mindful of that. First, upload necessary package(s). library(dplyr) # uplaods the function filter() and %&gt;% library(rafalib) # important for plotting with base R library(genefilter) # rowttests #library(devtools) # allows download from github library(GSE5859Subset) # subset of gene expression data library(tissuesGeneExpression) data(tissuesGeneExpression) library(RColorBrewer) ## Warning: package &#39;RColorBrewer&#39; was built under R version 3.5.2 library(caret) # for createFold ## Warning: package &#39;caret&#39; was built under R version 3.5.3 ## ## Attaching package: &#39;caret&#39; ## The following object is masked from &#39;package:survival&#39;: ## ## cluster library(gplots) # for heatmap ## ## Attaching package: &#39;gplots&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## lowess library(class) # for knn library(matrixStats) ## Warning: package &#39;matrixStats&#39; was built under R version 3.5.3 ## ## Attaching package: &#39;matrixStats&#39; ## The following objects are masked from &#39;package:Biobase&#39;: ## ## anyMissing, rowMedians ## The following objects are masked from &#39;package:genefilter&#39;: ## ## rowSds, rowVars ## The following object is masked from &#39;package:dplyr&#39;: ## ## count 9.2 Exercises Question 1 Create a random matrix with no correlation in the following way: set.seed(1) m = 10000 n = 24 x = matrix(rnorm(m*n),m,n) colnames(x)=1:n Run hierarchical clustering on this data with the hclust function with default parameters to cluster the columns. Create a dendrogram. In the dendrogram, which pairs of samples are the furthest away from each other? d &lt;- dist(t(x)) hc &lt;- hclust(d) mypar() plot(hc) #7 and 23 - 141 # 19 and 14 - 143 # 1 and 16 - 142 # 17 and 18 - 142 The answer is B: 19 and 14. The answer might be different due to the random numbers. Question 2 Set the seed at 1, set.seed(1) and replicate the creation of this matrix 100 times: m = 10000 n = 24 x = matrix(rnorm(m*n),m,n) then perform hierarchical clustering as in the solution to Question 1, and find the number of clusters if you use cuttree at height 143. This number is a random variable. Based on the Monte Carlo simulation, what is the standard error of this random variable? set.seed(1) res_list &lt;- replicate(100, { m = 10000 n = 24 x = matrix(rnorm(m*n),m,n) d &lt;- dist(t(x)) hc &lt;- hclust(d) hclusters &lt;- cutree(hc, h=143) num_clus &lt;- length(unique(hclusters)) return(num_clus) }) popsd(res_list) ## [1] 0.8986657 Question 3 Run kmeans with 4 centers for the blood RNA data: library(GSE5859Subset) data(GSE5859Subset) Set the seed to 10, set.seed(10) right before running kmeans with 5 centers. Explore the relationship of clusters and information in sampleInfo. Which of the following best describes what you find? km &lt;- kmeans(t(geneExpression), centers = 5) km$cluster ## GSM136508.CEL.gz GSM136530.CEL.gz GSM136517.CEL.gz ## 2 1 1 ## GSM136576.CEL.gz GSM136566.CEL.gz GSM136574.CEL.gz ## 5 3 5 ## GSM136575.CEL.gz GSM136569.CEL.gz GSM136568.CEL.gz ## 5 4 5 ## GSM136559.CEL.gz GSM136565.CEL.gz GSM136573.CEL.gz ## 3 3 4 ## GSM136523.CEL.gz GSM136509.CEL.gz GSM136727.CEL.gz ## 1 2 2 ## GSM136510.CEL.gz GSM136515.CEL.gz GSM136522.CEL.gz ## 2 2 1 ## GSM136507.CEL.gz GSM136524.CEL.gz GSM136514.CEL.gz ## 2 1 1 ## GSM136563.CEL.gz GSM136564.CEL.gz GSM136572.CEL.gz ## 3 3 4 table(true = sampleInfo$group, cluster = km$cluster) ## cluster ## true 1 2 3 4 5 ## 0 4 5 2 1 0 ## 1 2 1 3 2 4 table(true = sampleInfo$date, cluster = km$cluster) ## cluster ## true 1 2 3 4 5 ## 2005-06-10 0 1 0 0 0 ## 2005-06-23 1 5 0 0 0 ## 2005-06-27 5 0 0 0 0 ## 2005-10-07 0 0 5 3 2 ## 2005-10-28 0 0 0 0 2 The answer is C: Date is driving the clusters. Question 4 Load the data: library(GSE5859Subset) data(GSE5859Subset) Pick the 25 genes with the highest across sample variance. This function might help: library(matrixStats) Use heatmap.2 to make a heatmap showing the sampleInfo$group with color, the date as labels, the rows labelled with chromosome, and scaling the rows. What do we learn from this heatmap? hmcol &lt;- colorRampPalette(brewer.pal(9, &quot;GnBu&quot;))(100) month = format( sampleInfo$date, &quot;%m&quot;) rv &lt;- rowVars(geneExpression) idx &lt;- order(-rv)[1:25] cols &lt;- palette(brewer.pal(8, &quot;Dark2&quot;))[as.fumeric(as.character(sampleInfo$group))] heatmap.2(geneExpression[idx,], trace = &#39;none&#39;, labRow = geneAnnotation[idx,]$CHR, col = hmcol, labCol = month, ColSideColors = cols) The correct answer is C: A group of chrY genes are higher in group 0 and appear to drive the clustering. Within those clusters there appears to be clustering by month. I thought this question was tricky because it was not straightforward for me to draw the heatmap with many inputs. First, the orange and green colors represent the sample group (0 or 1). This was established in the code cols &lt;- palette(brewer.pal(8, \"Dark2\"))[as.fumeric(as.character(sampleInfo$group))] which then acted as input for ColSideColors in heatmap.2 function. labRow refers to the labelling of row, which in this case is chromosome geneAnnotation[idx,]$CHR. labCol has nothing to do with color; it has to do with column labelling, which in this case is month. col represents color for the values of the data geneExpression[idx,]. Answer A is wrong because if the data were generated by norm, the color distribution of the heatmap would be entirely random. Answer B is wrong because the colors in the row chr1 are more or less the same except for one column (one sample). Answer D is wrong chrY genes are higher in June, not October. Question 5 Create a large dataset of random data that is completely independent of sampleInfo$group like this: set.seed(17) m = nrow(geneExpression) n = ncol(geneExpression) x = matrix(rnorm(m*n),m,n) g = factor(sampleInfo$g) Create two heatmaps with these data. Show the group g either with labels or colors. First, take the 50 genes with smallest p-values obtained with rowttests. Then, take the 50 genes with largest standard deviations. Which of the following statements is true? # p-value pvals &lt;- rowttests(x, g)$p.value idx &lt;- order(pvals)[1:50] cols &lt;- palette(brewer.pal(8, &quot;Dark2&quot;))[as.fumeric(as.character(sampleInfo$g))] heatmap.2(x[idx,], trace = &#39;none&#39;, labRow = geneAnnotation[idx,]$CHR, col = hmcol, labCol = month, ColSideColors = cols) # std dev sds &lt;- genefilter::rowSds(x,g) idx &lt;- order(-sds)[1:50] cols &lt;- palette(brewer.pal(8, &quot;Dark2&quot;))[as.fumeric(as.character(sampleInfo$g))] heatmap.2(x[idx,], trace = &#39;none&#39;, labRow = geneAnnotation[idx,]$CHR, col = hmcol, labCol = month, ColSideColors = cols) The answer is A: There is no relationship between g and x, but with 8,793 tests some will appear significant by chance. Selecting genes with the t-test gives us a deceiving result. Recall that we have already selected smallest p-values from a dataset in which the null hypothesis is true. Therefore, we can see clusters that indicate that there is a significant difference between sample groups. However, this significance is not real because we know that the null hypothesis is true. 9.4 Exercises Question 1 Generate some random data to imitate heights for men (0) and women (1): n = 10000 set.seed(1) men = rnorm(n,176,7) #height in centimeters women = rnorm(n,162,7) #height in centimeters y = c(rep(0,n),rep(1,n)) x = round(c(men,women)) ##mix it up ind = sample(seq(along=y)) y = y[ind] x = x[ind] Using the data generated above, what is the \\(E(Y|X=176)\\) (proportion of females)? mean(y[x==176]) ## [1] 0.1049475 Question 2 Now make a plot of \\(E(Y|X=x)\\) for x=seq(160,178) using the data generated in Question 1. If you are predicting female or male based on height and want your probability of success to be larger than 0.5, what is the largest height where you predict female? mypar() plot(x,y) x_list &lt;- seq(160,178) res &lt;- vector(&#39;double&#39;, length(x_list)) for (i in seq_along(x_list)) { res[[i]] &lt;- mean(y[x==x_list[[i]]]) } ind &lt;- max(which(res &gt; 0.5)) x_list[ind] # answer ## [1] 168 mean(y[x==168]) ## [1] 0.5787172 9.8 Exercises Question 1 Generate the following data: n = 10000 set.seed(1) men = rnorm(n,176,7) #height in centimeters women = rnorm(n,162,7) #height in centimeters y = c(rep(0,n),rep(1,n)) x = round(c(men,women)) ##mix it up ind = sample(seq(along=y)) y = y[ind] x = x[ind] Set the seed at 5, set.seed(5) and take a random sample of 250 from: set.seed(5) N = 250 ind = sample(length(y),N) Y = y[ind] X = x[ind] Use loess to estimate \\(f(x) = E(Y|X=x)\\) using the default parameters. What is the predicted \\(f(168)\\)? fit &lt;- loess(Y~X) newx &lt;- seq(min(X),max(X),len=45) hat &lt;- predict(fit, newdata=data.frame(X=newx)) mypar() plot(X,Y) names(hat) &lt;- round(newx,1) lines(newx,hat) hat[&#39;168&#39;] ## 168 ## 0.5480233 Question 2 The loess estimate above is a random variable. We can compute standard errors for it. Here we use Monte Carlo to demonstrate that it is a random variable. Use Monte Carlo simulation to estimate the standard error of your estimate of \\(f(168)\\). Set the seed to 5, set.seed(5) and perform 10,000 simulations and report the SE of the loess based estimate. set.seed(5) B &lt;- 10000 N &lt;- 250 newx &lt;- seq(min(X),max(X),len=45) res &lt;- replicate(B, { ind = sample(length(y),N) Y = y[ind] X = x[ind] fit &lt;- loess(Y~X) hat &lt;- predict(fit, newdata=data.frame(X=newx)) names(hat) &lt;- round(newx,1) return(hat[&#39;168&#39;]) }) names(res) &lt;- NULL popsd(res) ## [1] 0.05618195 9.11 Exercises Load the following dataset: library(GSE5859Subset) data(GSE5859Subset) And define the outcome and predictors. To make the problem more dificult, we will only consider autosomal genes: y = factor(sampleInfo$group) X = t(geneExpression) out = which(geneAnnotation$CHR%in%c(&quot;chrX&quot;,&quot;chrY&quot;)) X = X[,-out] Question 1 Use the createFold function in the caret package, set the seed to 1 set.seed(1) and create 10 folds of y. What are the 2nd entry in the fold 3? library(caret) set.seed(1) idx &lt;- createFolds(y, k = 10) idx[[3]][2] ## [1] 15 Question 2 We are going to use kNN. We are going to consider a smaller set of predictors by using filtering gene using t-tests. Specifically, we will perform a t-test and select the \\(m\\) genes with the smallest p-values. Let m = 8 and k = 5 and train kNN by leaving out the second fold idx[[2]]. How many mistakes do we make on the test set? Remember it is indispensable that you perform the t-test on the training data. Use all 10 folds, keep k = 5. Hint: be careful about indexing. m &lt;- 8 # number of genes pvals &lt;- rowttests(t(X[-idx[[2]],]),y[-idx[[2]]])$p.value ind &lt;- order(pvals)[1:m] pred &lt;- knn(train = X[-idx[[2]],ind], test = X[idx[[2]],ind], cl = y[-idx[[2]]], k = 5) sum(pred != y[idx[[2]]]) ## [1] 1 When performing rowttests it is important to exclude test data. Indexing becomes quite tricky because you need to separate training and test data. Question 3 Now run through all 5 folds. What is our error rate (total number of errors / total predictions)? n_fold &lt;- length(idx) res &lt;- vector(&#39;double&#39;, n_fold) m &lt;- 8 for (i in seq(n_fold)) { pvals &lt;- rowttests(t(X[-idx[[i]],]),y[-idx[[i]]])$p.value ind &lt;- order(pvals)[1:m] pred &lt;- knn(train = X[-idx[[i]],ind], test = X[idx[[i]],ind], cl = y[-idx[[i]]], k = 5) res[[i]] &lt;- sum(pred != y[idx[[i]]]) } sum(res)/length(y) ## [1] 0.375 Question 4 Now we are going to select the best values of k and m. Use the expand.grid function to try out the following values: ms=2^c(1:11) ks=seq(1,9,2) params = expand.grid(k=ks,m=ms) Now use sapply or a for-loop to obtain error rates for each of these pairs of parameters. Which pair of parameters minimizes the error rate? Like previously, use the same p-values that you selected from the training data alone, and loop over 10 folds. ms = 2^c(1:11) ks = seq(1,9,2) params = expand.grid(k=ks, m=ms) n_fold &lt;- length(idx) error_rate_avg = vector(&#39;double&#39;,nrow(params)) for (j in seq(nrow(params))) { for (i in seq(n_fold)) { pvals &lt;- rowttests(t(X[-idx[[i]],]),y[-idx[[i]]])$p.value ind &lt;- order(pvals)[1:params[j,][[2]]] pred &lt;- knn(train = X[-idx[[i]],ind], test = X[idx[[i]],ind], cl = y[-idx[[i]]], k = params[j,][[1]]) res[[i]] &lt;- sum(pred != y[idx[[i]]]) } error_rate_avg[[j]] &lt;- sum(res)/length(y) } ind &lt;- which(error_rate_avg == min(error_rate_avg)) params[ind,] # answer ## k m ## 47 3 1024 min(error_rate_avg) # minimum error rate ## [1] 0.2083333 Question 5 Repeat Question 4, but now perform the t-test filtering before the cross validation. Note how this biases the entire result and gives us much lower estimated error rates. What is the minimum error rate? ms = 2^c(1:11) ks = seq(1,9,2) params = expand.grid(k=ks, m=ms) n_fold &lt;- length(idx) error_rate_avg = vector(&#39;double&#39;,nrow(params)) for (j in seq(nrow(params))) { for (i in seq(n_fold)) { pvals &lt;- rowttests(t(X),y)$p.value ind &lt;- order(pvals)[1:params[j,][[2]]] pred &lt;- knn(train = X[-idx[[i]],ind], test = X[idx[[i]],ind], cl = y[-idx[[i]]], k = params[j,][[1]]) res[[i]] &lt;- sum(pred != y[idx[[i]]]) } error_rate_avg[[j]] &lt;- sum(res)/length(y) } min(error_rate_avg) # minimum error rate ## [1] 0.08333333 mean(error_rate_avg) # mean error rate ## [1] 0.1833333 The error rate is much lower than the one in Question 4 because we did not filter out p values from the test data in this case. This is not a correct practice. The practice shown in Question 4 is correct. Question 6 Repeat Question 3, but now, instead of sampleInfo$group, use y = factor(as.numeric(format( sampleInfo$date, &quot;%m&quot;)==&quot;06&quot;)) What is the minimum error rate now? ms = 2^c(1:11) ks = seq(1,9,2) params = expand.grid(k=ks, m=ms) n_fold &lt;- length(idx) error_rate_avg = vector(&#39;double&#39;,nrow(params)) for (j in seq(nrow(params))) { for (i in seq(n_fold)) { pvals &lt;- rowttests(t(X[-idx[[i]],]),y[-idx[[i]]])$p.value ind &lt;- order(pvals)[1:params[j,][[2]]] pred &lt;- knn(train = X[-idx[[i]],ind], test = X[idx[[i]],ind], cl = y[-idx[[i]]], k = params[j,][[1]]) res[[i]] &lt;- sum(pred != y[idx[[i]]]) } error_rate_avg[[j]] &lt;- sum(res)/length(y) } min(error_rate_avg) # minimum error rate ## [1] 0 mean(error_rate_avg) # mean error rate ## [1] 0.06060606 "],
["batch-effects.html", "Chapter 10 Batch Effects 10.3 Exercises 10.6 Exercises 10.9 Exercises 10.11 Exercises 10.13 Exercises", " Chapter 10 Batch Effects Note: I have rephrased some parts of the questions for clarity. These changes are bolded. Due to the random numbers, the exact values of the answers, despite the same seeds, might differ. So please be mindful of that. First, upload necessary package(s). library(dplyr) # uplaods the function filter() and %&gt;% library(rafalib) # important for plotting with base R library(genefilter) # rowttests library(Biobase) ##available from Bioconductor library(genefilter) library(GSE5859) ##available from github data(GSE5859) library(GSE5859Subset) # subset of gene expression data library(tissuesGeneExpression) data(tissuesGeneExpression) library(qvalue) 10.3 Exercises Load the admissions data from the dagdata package (which is available from the genomicsclass repository): library(dagdata) data(admissions) Familiarize yourself with this table: admissions Question 1 Let’s compute the proportion of men who were accepted: index = which(admissions$Gender==1) accepted= sum(admissions$Number[index] * admissions$Percent[index]/100) applied = sum(admissions$Number[index]) accepted/applied ## [1] 0.4451951 What is the proportion of women that were accepted? index &lt;- admissions$Gender == 1 men &lt;- admissions[index,] women &lt;- admissions[!index,] menYes &lt;- sum(men$Percent/100 * men$Number) menNo &lt;- sum((1 - men$Percent/100) * men$Number) womenYes &lt;- sum(women$Percent/100 * women$Number) womenNo &lt;- sum((1-women$Percent/100) * women$Number) tab &lt;- matrix(c(menYes,womenYes,menNo,womenNo),2,2) print(womenYes/(womenYes+womenNo)) ## [1] 0.3033351 Question 2 Now that we have observed different acceptance rates between genders, test for the significance of this result. If you perform an independence test, what is the p-value? chisq.test(tab)$p.value ## [1] 9.139492e-22 Question 3 We can quantify how “hard” a major is by using the percent of students that were accepted. Compute the percent that were accepted (regardless of gender) to each major and call this vector H. Which is the hardest major? admissions1 &lt;- admissions %&gt;% mutate(accepted = Number * Percent/100) admissions2 &lt;- cbind(admissions1[1:6,c(1,2,5)], admissions1[7:12,c(2,5)]) colnames(admissions2) &lt;- c(&#39;major&#39;,&#39;number_m&#39;,&#39;accepted_m&#39;, &#39;number_f&#39;, &#39;accepted_f&#39;) admission3 &lt;- admissions2 %&gt;% group_by(major) %&gt;% transmute(total_number= number_m+number_f, total_accepted= accepted_m + accepted_f, proportion = total_accepted/total_number) H &lt;- admission3 %&gt;% dplyr::select(major,proportion) H ## # A tibble: 6 x 2 ## # Groups: major [6] ## major proportion ## &lt;fct&gt; &lt;dbl&gt; ## 1 A 0.643 ## 2 B 0.632 ## 3 C 0.351 ## 4 D 0.339 ## 5 E 0.253 ## 6 F 0.0648 Major F is the hardest major. Question 4 What proportion is accepted for this major? H[H$major == &#39;F&#39;, ] ## # A tibble: 1 x 2 ## # Groups: major [1] ## major proportion ## &lt;fct&gt; &lt;dbl&gt; ## 1 F 0.0648 Question 5 For men, what is the correlation between the number of applications across majors and H? cor.test(men$Number,H$proportion)$estimate ## cor ## 0.7647567 Question 6 For women, what is the correlation between the number of applications across majors and H? cor.test(women$Number,H$proportion)$estimate ## cor ## -0.6743393 Question 7 Given the answers to the above, which best explains the differences in admission percentages when we combine majors? The answer is C: There is confounding between gender and preference for “hard” majors: females are more likely to apply to harder majors. 10.6 Exercises library(Biobase) library(GSE5859) data(GSE5859) geneExpression = exprs(e) sampleInfo = pData(e) Familiarize yourself with the sampleInfo table. Note that some samples were processed at different times. This is an extraneous variable and should not affect the values in geneExpression. However, as we have seen in previous analyses, it does appear to have an effect so we will explore this here. You can extract the year from each date like this: year = format(sampleInfo$date,&quot;%y&quot;) Note that ethnic group and year is almost perfectly confounded: table(year,sampleInfo$ethnicity) ## ## year ASN CEU HAN ## 02 0 32 0 ## 03 0 54 0 ## 04 0 13 0 ## 05 80 3 0 ## 06 2 0 24 Question 1 For how many of these years do we have more than one ethnicity represented? table(year,sampleInfo$ethnicity) ## ## year ASN CEU HAN ## 02 0 32 0 ## 03 0 54 0 ## 04 0 13 0 ## 05 80 3 0 ## 06 2 0 24 Two of the years have more than one ethnicity represented. Question 2 Repeat the above exercise, but now, instead of year, consider the month as well. Specifically, instead of the year variable defined above use: month.year = format(sampleInfo$date,&quot;%m%y&quot;) For what proportion of these month.year values do we have more than one ethnicity represented? month.year = format(sampleInfo$date,&quot;%m%y&quot;) tab &lt;- table(month.year, sampleInfo$ethnicity) res &lt;- vector(&#39;double&#39;, nrow(tab)) for (i in seq_along(res)) { res[[i]] &lt;- length(unique(tab[i,])) } mean(res==3) ## [1] 0.04761905 Question 3 Perform a t-test (use rowttests) comparing CEU samples processed in 2002 to those processed in 2003. Then use the qvalue package to obtain q-values for each gene. How many genes have q-values &lt; 0.05? eth &lt;- sampleInfo$ethnicity ind &lt;- which(eth == &#39;CEU&#39; &amp; year %in% c(&#39;02&#39;,&#39;03&#39;)) pvals &lt;- rowttests(geneExpression[,ind], factor(year[ind]))$p.value qvals &lt;- qvalue(pvals)$qvalues sum(qvals &lt; 0.05) ## [1] 4308 Question 4 What is the estimate of pi0 provided by qvalue? qvalue(pvals)$pi0 ## [1] 0.3628642 Question 5 Now perform a t-test (use rowttests) comparing CEU samples processed in 2003 to those processed in 2004. Then use the qvalue package to obtain q-values for each gene. How many genes have q-values less than 0.05? ind &lt;- which(eth == &#39;CEU&#39; &amp; year %in% c(&#39;03&#39;,&#39;04&#39;)) pvals &lt;- rowttests(geneExpression[,ind], factor(year[ind]))$p.value qvals &lt;- qvalue(pvals)$qvalues sum(qvals &lt; 0.05) ## [1] 2463 Question 6 Now we are going to compare ethnicities as was done in the original publication in which these data were first presented. Use the qvalue function to compare the ASN population to the CEU population. Once again, use the qvalue function to obtain q-values. How many genes have q-values &lt; 0.05? ind &lt;- which(eth %in% c(&#39;ASN&#39;,&#39;CEU&#39;)) pvals &lt;- rowttests(geneExpression[,ind], factor(eth[ind]))$p.value qvals &lt;- qvalue(pvals)$qvalues sum(qvals &lt; 0.05) ## [1] 7217 Question 7 Over 80% of genes are called differentially expressed between ethnic groups. However, due to the confounding with processing date, we need to confirm these differences are actually due to ethnicity.This will not be easy due to the almost perfect confounding. However, above we noted that two groups were represented in 2005. Just like we stratified by majors to remove the “major effect” in our admissions example, here we can stratify by year and perform a t-test comparing ASN and CEU, but only for samples processed in 2005. How many genes have q-values &lt; 0.05? ind &lt;- which(eth %in% c(&#39;ASN&#39;,&#39;CEU&#39;)&amp; year == &#39;05&#39;) pvals &lt;- rowttests(geneExpression[,ind], factor(eth[ind]))$p.value qvals &lt;- qvalue(pvals)$qvalues sum(qvals &lt; 0.05) ## [1] 560 table(sampleInfo$ethnicity[ind]) ## ## ASN CEU HAN ## 80 3 0 Question 8 To provide a more balanced comparison, we repeat the analysis, but now taking 3 random CEU samples from 2002. Repeat the analysis above, but comparing the ASN from 2005 to three random CEU samples from 2002. Set the seed at 3, set.seed(3). How many genes have q-values &lt; 0.05? set.seed(3) ind_ceu &lt;- which(eth ==&#39;CEU&#39; &amp; year == &#39;02&#39;) ind_ceu2 &lt;- sample(ind_ceu,3) ind_asn &lt;- which(eth == &#39;ASN&#39; &amp; year ==&#39;05&#39;) ind &lt;- c(ind_ceu2,ind_asn) pvals &lt;- rowttests(geneExpression[,ind], factor(eth[ind]))$p.value qvals &lt;- qvalue(pvals)$qvalues sum(qvals &lt; 0.05) ## [1] 3695 10.9 Exercises library(GSE5859Subset) data(GSE5859Subset) sex = sampleInfo$group month = factor( format(sampleInfo$date,&quot;%m&quot;)) table( sampleInfo$group, month) ## month ## 06 10 ## 0 9 3 ## 1 3 9 Question 1 Using the functions rowttests and qvalue compare the two groups. Because this is a smaller dataset which decreases our power, we will use the more lenient FDR cut-off of 10%. How many gene have q-values less than 0.1? pvals &lt;- rowttests(geneExpression, factor(sex))$p.val qvals &lt;- qvalue(pvals)$qvalues sum(qvals&lt;0.1) ## [1] 59 Question 2 Note that sampleInfo$group here presents males and females. Thus, we expect differences to be in on chrY and, for genes that escape inactivation, chrX. We do not expect many autosomal genes to be different between males and females. This gives us an opportunity to evaluate false and true positives with experimental data. For example, we evaluate results using the proportion genes of the list that are on chrX or chrY. For the list calculated in Question 1, what proportion of this list is on chrX or chrY? ind_qval &lt;- (qvals&lt;0.1) # qvalue index for significance chr &lt;- geneAnnotation$CHR ind_xy &lt;- (chr[ind_qval] %in% c(&#39;chrX&#39;,&#39;chrY&#39;)) sum(ind_xy)/sum(ind_qval) ## [1] 0.3389831 Question 3 We can also check how many of the chromosomes X and Y genes we detected as different. How many are on Y? chr_ind_xy &lt;- which(chr[ind_qval] %in% c(&#39;chrX&#39;,&#39;chrY&#39;)) length(chr[ind_qval][chr_ind_xy] == &#39;chrY&#39;) ## [1] 20 Question 4 Now for the autosomal genes (not on chrX and chrY) for which q-value &lt; 0.1, perform a t-test comparing samples processed in June to those processed in October. What proportion of these have p-values &lt;0.05? Hint: Be careful about indexing. pvals &lt;- rowttests(geneExpression, factor(sex))$p.val qvals &lt;- qvalue(pvals)$qvalues ind &lt;- which(qvals &lt; 0.1) gene_dat_non_xy &lt;- geneExpression[ind[!chr[ind] %in% c(&#39;chrX&#39;,&#39;chrY&#39;)],] pvals &lt;- rowttests(gene_dat_non_xy, factor(month))$p.val mean(pvals &lt; 0.05) ## [1] 0.8717949 Question 5 The above result shows that the great majority of the autosomal genes show differences due to processing data. This provides further evidence that confounding is resulting in false positives. So we are going to try to model the month effect to better estimate the sex effect. We are going to use a linear model. Which of the following creates the appropriate design matrix? batch &lt;- factor(month) model.matrix(~sex+batch) # answer D ## (Intercept) sex batch10 ## 1 1 1 0 ## 2 1 1 0 ## 3 1 1 0 ## 4 1 1 1 ## 5 1 1 1 ## 6 1 1 1 ## 7 1 1 1 ## 8 1 1 1 ## 9 1 1 1 ## 10 1 1 1 ## 11 1 1 1 ## 12 1 1 1 ## 13 1 0 0 ## 14 1 0 0 ## 15 1 0 0 ## 16 1 0 0 ## 17 1 0 0 ## 18 1 0 0 ## 19 1 0 0 ## 20 1 0 0 ## 21 1 0 0 ## 22 1 0 1 ## 23 1 0 1 ## 24 1 0 1 ## attr(,&quot;assign&quot;) ## [1] 0 1 2 ## attr(,&quot;contrasts&quot;) ## attr(,&quot;contrasts&quot;)$batch ## [1] &quot;contr.treatment&quot; Question 6 Now use the X defined above, to fit a regression model using lm for each gene. You can obtain p-values for estimated parameters using summary. Here is an example X = model.matrix(~sex+month) i = 234 y = geneExpression[i,] fit = lm(y~X) summary(fit)$coef ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 9.33316105 0.06098459 153.0412990 1.714250e-33 ## Xsex -0.04281057 0.09220004 -0.4643227 6.471942e-01 ## Xmonth10 0.25352885 0.09220004 2.7497696 1.200505e-02 How many of the q-values for the group comparison are now &lt;0.1? Note the big drop from what we obtained without the correction (Question 1). X &lt;- model.matrix(~sex+month) res &lt;- t(sapply(1:nrow(geneExpression), function(i) { fit &lt;- lm(geneExpression[i,]~X) return(summary(fit)$coef[2,c(1,4)]) })) res &lt;- data.frame(res) names(res) &lt;- c(&#39;est&#39;,&#39;pvals&#39;) qvals &lt;- qvalue(res$pvals)$qvalues sum(qvals &lt;0.1) ## [1] 17 Question 7 With this new list, what proportion of these are chrX and chrY? Notice the big improvement. ind_qval &lt;- (qvals&lt;0.1) chr &lt;- geneAnnotation$CHR ind_xy &lt;- (chr[ind_qval] %in% c(&#39;chrX&#39;,&#39;chrY&#39;)) # index for chrX and chrY sum(ind_xy)/sum(ind_qval) ## [1] 0.8823529 Question 8 How many on Y or X? sum(ind_xy) ## [1] 15 Question 9 Now from the linear model above, extract the p-values related to the coeffcient representing the October versus June differences using the same linear model. How many of the q-values for the month comparison are now &lt;0.1? This approach is basically the approach implemented by Combat. X &lt;- model.matrix(~sex+month) res &lt;- t(sapply(1:nrow(geneExpression), function(i) { fit &lt;- lm(geneExpression[i,]~X) return(summary(fit)$coef[3,c(1,4)]) })) res &lt;- data.frame(res) names(res) &lt;- c(&#39;est&#39;,&#39;pvals&#39;) qvals &lt;- qvalue(res$pvals)$qvalues sum(qvals &lt;0.1) ## [1] 3170 10.11 Exercises Question 1 Suppose you want to make an MA-plot of the first two samples y = geneExpression[,1:2]. Which of the following projections gives us the projection of y so that column 2 versus column 1 is an MA plot? \\[ \\, A. y\\begin{pmatrix} 1/\\sqrt{2} &amp; 1/\\sqrt{2} \\\\ 1/\\sqrt{2} &amp; -1/\\sqrt{2} \\\\ \\end{pmatrix} \\\\ B. y\\begin{pmatrix} 1 &amp; 1 \\\\ 1 &amp; -1 \\\\ \\end{pmatrix} \\\\ C. \\begin{pmatrix} 1 &amp; 1 \\\\ 1 &amp; -1 \\\\ \\end{pmatrix} y \\\\ D. \\begin{pmatrix} 1 &amp; 1 \\\\ 1 &amp; -1 \\\\ \\end{pmatrix} y^T \\] To be honest, according to my attempt, there’s no correct answer among the provided answer choices. Please let me know if I am incorrect (through github or email); I will make sure to put your name in one of the contributors to this project. Here’s my attempt. y = geneExpression[,1:2] avg = (y[,1]+y[,2])/2 # average diff = z2 = (y[,1]-y[,2]) # difference z = cbind(avg,diff) head(z) # the actual values of average and difference ## avg diff ## 1007_s_at 6.472712 0.14248432 ## 1053_at 7.405128 0.28316044 ## 117_at 5.226584 0.35207594 ## 121_at 7.800149 0.18478972 ## 1255_g_at 3.232791 0.01997527 ## 1294_at 7.311012 0.44148316 # Now let&#39;s try each answer and compare to head(z). # answer A - avg = sqrt(2) x z[,1], diff = z[,2] / sqrt(2) head(y %*% matrix(c(1,1,1,-1),2,2)) ## [,1] [,2] ## 1007_s_at 12.945424 0.14248432 ## 1053_at 14.810255 0.28316044 ## 117_at 10.453168 0.35207594 ## 121_at 15.600297 0.18478972 ## 1255_g_at 6.465583 0.01997527 ## 1294_at 14.622024 0.44148316 # answer B - avg = 2 x z[1,2], diff = z[,2] head(y %*% matrix(c(1,1,1,-1),2,2)) ## [,1] [,2] ## 1007_s_at 12.945424 0.14248432 ## 1053_at 14.810255 0.28316044 ## 117_at 10.453168 0.35207594 ## 121_at 15.600297 0.18478972 ## 1255_g_at 6.465583 0.01997527 ## 1294_at 14.622024 0.44148316 # answer C - non-comfortable array, can&#39;t multiply # answer D - avg = 2 x z[1,2], diff = z[,2] head(t(matrix(c(1,1,1,-1),2,2) %*% t(y))) ## [,1] [,2] ## 1007_s_at 12.945424 0.14248432 ## 1053_at 14.810255 0.28316044 ## 117_at 10.453168 0.35207594 ## 121_at 15.600297 0.18478972 ## 1255_g_at 6.465583 0.01997527 ## 1294_at 14.622024 0.44148316 So none of the choices are equal to head(z). Instead here is my answer that transforms y correctly. ans &lt;- head(y %*% matrix(c(1/2,1/2,1,-1),2,2)) ans ## [,1] [,2] ## 1007_s_at 6.472712 0.14248432 ## 1053_at 7.405128 0.28316044 ## 117_at 5.226584 0.35207594 ## 121_at 7.800149 0.18478972 ## 1255_g_at 3.232791 0.01997527 ## 1294_at 7.311012 0.44148316 identical(z, ans) # they are identical ## [1] FALSE Therefore, my answer is: \\[ y\\begin{pmatrix} 1/2 &amp; 1 \\\\ 1/2 &amp; -1 \\\\ \\end{pmatrix} \\\\ \\] Question 2 Say \\(Y\\) is \\(M\\)x\\(N\\) in the \\(SVD Y = UDV^T\\) which of the following is not correct? Answer is C: \\(D\\) are the coordinates of the projection \\(U^TY\\). Question 3 Define y = geneExpression - rowMeans(geneExpression) Compute and plot an image of the correlation for each sample. Make two image plots of these correlations. In the first one, plot the correlation as image. In the second, order the samples by date and then plot an image of the correlation. The only difference in these plots is the order in which the samples are plotted. Based on these plots, which of the following would you say is true? n &lt;- ncol(y) cors=cor(y) cols=colorRampPalette(rev(brewer.pal(11,&quot;RdBu&quot;)))(100) image(1:n, 1:n, cors, col=cols, xlab = &#39;samples&#39;, ylab = &#39;samples&#39;, zlim = c(-1,1)) # correlation as image ind &lt;- order(sampleInfo$date) y2 &lt;- y[,ind] n2 &lt;- ncol(y) cors2=cor(y2) image(1:n2, 1:n2, cors2, col=cols, xlab = &#39;samples&#39;, ylab = &#39;samples&#39;, zlim = c(-1,1)) # correlation as image after sorting the date. some samples are more correlated within a span of date than others. The answer is D: The fact that in the plot ordered by month we see two groups mainly driven by month, and within these we see subgroups driven by date, seems to suggest date more than month per se are the hidden factors. Question 4 Based on the correlation plots above, we could argue that there are at least two hidden factors. Using PCA estimate these two factors. Specifically, apply the svd to y and use the first two PCs as estimates. Which command gives us these estimates? s &lt;- svd(y) head(s$v[,1:2]) ## [,1] [,2] ## [1,] -0.232970658 -0.01693543 ## [2,] -0.034229085 -0.13955710 ## [3,] -0.083264418 -0.19476886 ## [4,] 0.306299241 -0.07357253 ## [5,] 0.003861145 0.17918969 ## [6,] 0.353302375 -0.09079626 The answer is B: pcs = svd(y)$v[,1:2]. Question 5 Plot each of the estimated factors ordered by the date. Use color to denote month. The first factor is clearly related to date. Which of the following appears to be most different according to this factor? To be honest, I do not know what the question is actually asking for. I also think this is one of the most difficult questions in the book. It can possibly ask either of these two things: 1) which date appears to be most different in the function of PC1? 2) which dates are most different from each other in the function of PC1? To answer both of these questions, we need to visualize each date in a plot where the x-axis is PC1 and y-axis is PC2. My code below also displays the range of PC1 for each date blue. s &lt;- svd(y) ind_0610 &lt;- which(sampleInfo$date == &#39;2005-06-10&#39;) ind_0623 &lt;- which(sampleInfo$date == &#39;2005-06-23&#39;) ind_0627 &lt;- which(sampleInfo$date == &#39;2005-06-27&#39;) ind_1007 &lt;- which(sampleInfo$date == &#39;2005-10-07&#39;) ind_1028 &lt;- which(sampleInfo$date == &#39;2005-10-28&#39;) index_list &lt;- list(ind_0610, ind_0623, ind_0627, ind_1007, ind_1028) res_range &lt;- vector(&#39;double&#39;,length(index_list)) mypar(2,3) for (i in seq_along(index_list)) { plot(s$v[,1][index_list[[i]]], s$v[,2][index_list[[i]]], xlab = &#39;PC1&#39;, ylab = &#39;PC2&#39;, xlim = c(-0.4,.4), ylim = c(-0.4,0.6), main = paste0(unique(sampleInfo$date[index_list[[i]]]))) res_range[[i]] &lt;- max(s$v[,1][index_list[[i]]])-min(s$v[,1][index_list[[i]]]) text(0.1,0.1, signif(res_range[[i]],2), pos=2,col = &#39;blue&#39;) } The plot shows data that are spread in the function of PC1. The blue numbers show the range of PC1 that each date’s data span. Oct 7th has a highest difference in the function of PC1, with a range of 0.38. However, the range of Oct 28th is merely 0.075. Also they do not seem to be much different from each other, primarily because Oct 7th covers a wide range of PC1. This rules out answer choice B. June 10th and 23th seem to be not much different from each other. Also, the range of June 10th is 0 because it only has one point. This rules out answer choice C. Answer D is eliminated because there is no June 15th. Answer choice A seems to be most appropriate because both June 23th and 27th data seem to be spread in the function of PC1. Also they do seem to be quite different from each other in terms of their location in the PC1 x-axis. Question 6 Use the svd function to obtain the principal components (PCs) for our detrended gene expression data y. How many PCs explain more than 10% of the variability? y = geneExpression - rowMeans(geneExpression) s &lt;- svd(y) sum((s$d^2)/sum(s$d^2) &gt; 0.1) ## [1] 2 Question 7 Which PC most correlates (negative or positive correlation) with month? res &lt;- vector(&#39;double&#39;,ncol(s$v)) month &lt;- format(sampleInfo$date,&quot;%m&quot;) month &lt;- as.numeric(month) for (i in seq_along(res)) { res[[i]] &lt;- cor(month, s$v[,i]) } ind &lt;- which(abs(res)==max(abs(res))) ind ## [1] 1 Question 8 What is this correlation (in absolute value)? abs(res[ind]) ## [1] 0.8297915 Question 9 Which PC most correlates (negative or positive correlation) with sex? res &lt;- vector(&#39;double&#39;,ncol(s$v)) sex &lt;- sampleInfo$group for (i in seq_along(res)) { res[[i]] &lt;- cor(sex, s$v[,i]) } ind &lt;- which(abs(res)==max(abs(res))) ind ## [1] 1 Question 10 What is this correlation (in absolute value)? abs(res[ind]) ## [1] 0.6236858 Question 11 Now instead of using month, which we have shown does not quite describe the batch (Question 5), add the two estimated factors s$v[,1:2] to the linear model we used above. Apply this model to each gene and compute q-values for the sex difference. How many q-values &lt; 0.1 for the sex comparison? y = geneExpression - rowMeans(geneExpression) s &lt;- svd(y) X &lt;- model.matrix(~sex + s$v[,1:2]) res &lt;- sapply(1:nrow(y), function(i) { fit &lt;- lm(y[i,]~X) return(summary(fit)$coef[2,4]) }) qvals &lt;- qvalue(res)$qvalues sum(qvals &lt; 0.1) ## [1] 14 Question 12 What proportion of the genes are on chromosomes X and Y? chr &lt;- geneAnnotation$CHR ind &lt;- qvals &lt; 0.1 mean(chr[ind] %in% c(&#39;chrX&#39;,&#39;chrY&#39;)) ## [1] 1 10.13 Exercises library(sva) ## Warning: package &#39;sva&#39; was built under R version 3.5.2 ## Loading required package: mgcv ## Loading required package: nlme ## ## Attaching package: &#39;nlme&#39; ## The following object is masked from &#39;package:HistData&#39;: ## ## Wheat ## The following object is masked from &#39;package:dplyr&#39;: ## ## collapse ## This is mgcv 1.8-24. For overview type &#39;help(&quot;mgcv-package&quot;)&#39;. ## Loading required package: BiocParallel library(Biobase) library(GSE5859Subset) data(GSE5859Subset) Question 1 In a previous section we estimated factors using PCA, but we noted that the first factor was correlated with our outcome of interest: s &lt;- svd(geneExpression-rowMeans(geneExpression)) cor(sampleInfo$group,s$v[,1]) ## [1] 0.6236858 The svafit function estimates factors, but downweighs the genes that appear to correlate with the outcome of interest. It also tries to estimate the number of factors and returns the estimated factors like this: sex = sampleInfo$group mod = model.matrix(~sex) svafit = sva(geneExpression,mod) ## Number of significant surrogate variables is: 5 ## Iteration (out of 5 ):1 2 3 4 5 head(svafit$sv) ## [,1] [,2] [,3] [,4] [,5] ## [1,] -0.26862626 -0.03838109 0.15306742 -0.3007374 0.210098158 ## [2,] -0.06132157 -0.15755769 -0.03538763 0.0851655 -0.063869257 ## [3,] -0.12161818 -0.21766433 -0.12624414 0.2443445 -0.099004174 ## [4,] 0.30660574 -0.09657648 -0.32034135 -0.1680430 0.620260643 ## [5,] -0.01850853 0.18648507 0.17931970 0.4244993 -0.007840835 ## [6,] 0.36062840 -0.08542758 -0.10726746 0.1074114 0.033204590 The resulting estimated factors are not that different from the PCs. for(i in 1:ncol(svafit$sv)){ print( cor(s$v[,i],svafit$sv[,i]) ) } ## [1] 0.9944755 ## [1] 0.9964202 ## [1] -0.9915972 ## [1] -0.9896597 ## [1] -0.9518427 Now fit a linear model to each gene that instead of month includes these factors in the model. Use the qvalue function. How many genes have q-value &lt; 0.1? y &lt;- geneExpression - rowMeans(geneExpression) X &lt;- model.matrix(~sex + svafit$sv) res &lt;- sapply(1:nrow(y), function(i) { fit &lt;- lm(y[i,]~X) return(summary(fit)$coef[2,4]) }) qvals &lt;- qvalue(res)$qvalues sum(qvals &lt; 0.1) ## [1] 13 Question 2 How many of these genes are from chrY or chrX? chr &lt;- geneAnnotation$CHR ind &lt;- qvals &lt; 0.1 sum(chr[ind] %in% c(&#39;chrX&#39;,&#39;chrY&#39;)) ## [1] 12 "]
]
